
@inproceedings{lin_spectral-spatial_2013,
  title = {Spectral-Spatial Classification of Hyperspectral Image Using Autoencoders},
  booktitle = {Information, {{Communications}} and {{Signal Processing}} ({{ICICS}}) 2013 9th {{International Conference}} On},
  publisher = {{IEEE}},
  author = {Lin, Zhouhan and Chen, Yushi and Zhao, Xing and Wang, Gang},
  year = {2013},
  keywords = {À lire,Accuracy,autoencoders,deep learning,feature extraction,geophysical image processing,HSI classification,Hyperspectral,hyperspectral image classification,hyperspectral imaging,image classification,Neural networks,PCA,principal component analysis,remote sensing community,spectral dimension,spectral information,spectral spatial classification,spectral spatial feature extraction,spectral spatial information extraction,stacked autoencoders,support vector machines,SVM},
  pages = {1--5},
  file = {/home/naudeber/Bibliographie//IEEE/2013/Lin et al 2013 - Spectral-spatial classification of hyperspectral image using autoencoders.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/3D9647FX/6782778.html}
}

@article{chen_spectral-spatial_2015,
  title = {Spectral-{{Spatial Classification}} of {{Hyperspectral Data Based}} on {{Deep Belief Network}}},
  volume = {8},
  issn = {1939-1404, 2151-1535},
  doi = {10.1109/JSTARS.2015.2388577},
  number = {6},
  journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  author = {Chen, Yushi and Zhao, Xing and Jia, Xiuping},
  month = jun,
  year = {2015},
  keywords = {À lire,belief networks,Boltzmann machines,data analysis,DBN,deep belief network,Deep belief network (DBN),deep learning,deep learning approach,feature extraction,feature extraction (FE),hierarchical learning-based FE,hyperspectral data analysis,hyperspectral data classification,hyperspectral image classification,hyperspectral imaging,image classification,Iron,learning (artificial intelligence),logistic regression,logistic regression (LR),LR,PCA,principal component analysis,RBM,regression analysis,remote sensing,restricted Boltzmann machine,restricted Boltzmann machine (RBM),spectral information-based classification,spectral-spatial FE,spectral-spatial hyperspectral data classification,support vector machine (SVM),support vector machines,Training,Vectors},
  pages = {2381-2392},
  file = {/home/naudeber/Bibliographie//IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing/2015/Chen et al 2015 - Spectral-Spatial Classification of Hyperspectral Data Based on Deep Belief.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/ZSRUWSIT/7018910.html}
}

@article{le_bris_extraction_2015,
  title = {Extraction of Optimal Spectral Bands Using Hierarchical Band Merging out of Hyperspectral Data},
  volume = {XL-3/W3},
  issn = {2194-9034},
  doi = {10.5194/isprsarchives-XL-3-W3-459-2015},
  language = {en},
  journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  author = {Le Bris, A. and Chehata, N. and Briottet, X. and Paparoditis, N.},
  month = aug,
  year = {2015},
  pages = {459-465},
  file = {/home/naudeber/Bibliographie//ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences/2015/Le Bris et al 2015 - Extraction of optimal spectral bands using hierarchical band merging out of.pdf}
}

@inproceedings{li_classification_2014,
  title = {Classification of Hyperspectral Image Based on Deep Belief Networks},
  booktitle = {Image {{Processing}} ({{ICIP}}), 2014 {{IEEE International Conference}} On},
  publisher = {{IEEE}},
  author = {Li, Tong and Zhang, Junping and Zhang, Ye},
  year = {2014},
  keywords = {À lire,Accuracy,airborne hyperspectral image,belief networks,Boltzmann machines,classification,DBN,deep belief networks,deep learning,deep learning frameworks,deep structure deep belief networks,dimensionality reduction methods,feature extraction,geophysical image processing,Hyperspectral,hyperspectral image classification,hyperspectral image processing,hyperspectral imaging,image classification,information loss,learning (artificial intelligence),matrix decomposition,negative matrix factorization,Neural networks,NMF,PCA,principal component analysis,principle component analysis,RBM model,restricted Boltzmann machine model,spatial-spectral classification,support vector machine,support vector machines,SVM,Training},
  pages = {5132--5136},
  file = {/home/naudeber/Bibliographie//IEEE/2014/Li et al 2014 - Classification of hyperspectral image based on deep belief networks.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/CI932G38/7026039.html}
}

@article{lecun_gradient-based_1998,
  title = {Gradient-Based Learning Applied to Document Recognition},
  volume = {86},
  issn = {0018-9219},
  doi = {10.1109/5.726791},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day},
  number = {11},
  journal = {Proceedings of the IEEE},
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  month = nov,
  year = {1998},
  keywords = {2D shape variability,back-propagation,backpropagation,Character recognition,cheque reading,complex decision surface synthesis,convolution,convolutional neural network character recognizers,document recognition,document recognition systems,feature extraction,Feature extraction,field extraction,gradient based learning technique,gradient-based learning,graph transformer networks,GTN,handwritten character recognition,handwritten digit recognition task,Hidden Markov models,high-dimensional patterns,language modeling,Machine learning,Multi-layer neural network,multilayer neural networks,multilayer perceptrons,multimodule systems,Neural networks,optical character recognition,Optical character recognition software,Optical computing,Pattern recognition,Pattern Recognition,performance measure minimization,principal component analysis,Principal component analysis,segmentation recognition},
  pages = {2278-2324},
  file = {/home/naudeber/Bibliographie//Proceedings of the IEEE/1998/Lecun et al 1998 - Gradient-based learning applied to document recognition.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/ANY9HKIA/726791.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/HUI6PF8F/abs_all.html}
}

@article{chen_deep_2014,
  title = {Deep {{Learning}}-{{Based Classification}} of {{Hyperspectral Data}}},
  volume = {7},
  issn = {1939-1404},
  doi = {10.1109/JSTARS.2014.2329330},
  abstract = {Classification is one of the most popular topics in hyperspectral remote sensing. In the last two decades, a huge number of methods were proposed to deal with the hyperspectral data classification problem. However, most of them do not hierarchically extract deep features. In this paper, the concept of deep learning is introduced into hyperspectral data classification for the first time. First, we verify the eligibility of stacked autoencoders by following classical spectral information-based classification. Second, a new way of classifying with spatial-dominated information is proposed. We then propose a novel deep learning framework to merge the two features, from which we can get the highest classification accuracy. The framework is a hybrid of principle component analysis (PCA), deep learning architecture, and logistic regression. Specifically, as a deep learning architecture, stacked autoencoders are aimed to get useful high-level features. Experimental results with widely-used hyperspectral data indicate that classifiers built in this deep learning-based framework provide competitive performance. In addition, the proposed joint spectral-spatial deep neural network opens a new window for future research, showcasing the deep learning-based methods' huge potential for accurate hyperspectral data classification.},
  number = {6},
  journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  author = {Chen, Yushi and Lin, Zhouhan and Zhao, Xing and Wang, Gang and Gu, Yanfeng},
  month = jun,
  year = {2014},
  keywords = {À lire,Autoencoder (AE),classical spectral information-based classification,deep learning,deep learning architecture,deep learning-based classification,feature extraction,geophysical image processing,hyperspectral data classification,hyperspectral imaging,image classification,learning (artificial intelligence),logistic regression,Logistics,neural nets,principal component analysis,principle component analysis,regression analysis,remote sensing,spatial-dominated information,spectral-spatial deep neural network,stacked autoencoder (SAE),stacked autoencoders,support vector machine (SVM),support vector machines,Training},
  pages = {2094-2107},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/J2XRT4DN/abs_all.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/QVJCMZTH/6844831.html}
}

@article{romero_unsupervised_2015,
  title = {Unsupervised {{Deep Feature Extraction}} for {{Remote Sensing Image Classification}}},
  volume = {PP},
  issn = {0196-2892},
  doi = {10.1109/TGRS.2015.2478379},
  abstract = {This paper introduces the use of single-layer and deep convolutional networks for remote sensing data analysis. Direct application to multi- and hyperspectral imagery of supervised (shallow or deep) convolutional networks is very challenging given the high input data dimensionality and the relatively small amount of available labeled data. Therefore, we propose the use of greedy layerwise unsupervised pretraining coupled with a highly efficient algorithm for unsupervised learning of sparse features. The algorithm is rooted on sparse representations and enforces both population and lifetime sparsity of the extracted features, simultaneously. We successfully illustrate the expressive power of the extracted representations in several scenarios: classification of aerial scenes, as well as land-use classification in very high resolution or land-cover classification from multi- and hyperspectral images. The proposed algorithm clearly outperforms standard principal component analysis (PCA) and its kernel counterpart (kPCA), as well as current state-of-the-art algorithms of aerial classification, while being extremely computationally efficient at learning representations of data. Results show that single-layer convolutional networks can extract powerful discriminative features only when the receptive field accounts for neighboring pixels and are preferred when the classification requires high resolution and detailed results. However, deep architectures significantly outperform single-layer variants, capturing increasing levels of abstraction and complexity throughout the feature hierarchy.},
  number = {99},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Romero, A. and Gatta, C. and {Camps-Valls}, G.},
  year = {2015},
  keywords = {Aerial image classification,classification,Computer architecture,deep convolutional networks,deep learning,feature extraction,hyperspectral (HS) image,multispectral (MS) images,remote sensing,segmentation,Sociology,sparse features learning,Statistics,Training,Unsupervised learning,very high resolution (VHR)},
  pages = {1-14},
  file = {/home/naudeber/Bibliographie//IEEE Transactions on Geoscience and Remote Sensing/2016/Romero et al 2016 - Unsupervised Deep Feature Extraction for Remote Sensing Image Classification.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/NX3WDBIW/articleDetails.html}
}

@inproceedings{ben_hamida_deep_2016,
  address = {Santa Cruz de Tenerife, Spain},
  title = {Deep {{Learning Approach}} for {{Remote Sensing Image Analysis}}},
  doi = {10.2788/854791},
  abstract = {The paper explores how multimedia approaches used in image understanding tasks could be adapted for remote sensing image analysis. In a first step, we show on 3 channels color images through the UC Merced Land Use Dataset how Deep Learning approach provides a significant performance increase compared to Bag of VisualWords approach. In a second step, we propose an extension of deep learning scheme to deal with hyperspectral data. The proposed scheme is based on a 3D architecture which jointly processes spectral and spatial information.},
  booktitle = {Big {{Data}} from {{Space}} ({{BiDS}}'16)},
  publisher = {{Publications Office of the European Union}},
  author = {Ben Hamida, Amina and Benoit, Alexandre and Lambert, Patrick and Chokri Ben, Amar},
  editor = {Giorgio, SOILLE Pierre MARCHETTI Pier},
  month = mar,
  year = {2016},
  keywords = {classification,deep learning,Remote sensing image},
  pages = {133},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/XK4WMTKD/hal-01370161.html}
}

@article{srivastava_dropout_2014,
  title = {Dropout: {{A Simple Way}} to {{Prevent Neural Networks}} from {{Overfitting}}},
  volume = {15},
  shorttitle = {Dropout},
  journal = {Journal of Machine Learning Research},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  year = {2014},
  pages = {1929-1958},
  file = {/home/naudeber/Bibliographie//Journal of Machine Learning Research/2014/Srivastava et al 2014 - Dropout.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/CDBFKSEG/srivastava14a.html}
}

@inproceedings{makantasis_deep_2015,
  title = {Deep Supervised Learning for Hyperspectral Data Classification through Convolutional Neural Networks},
  doi = {10.1109/IGARSS.2015.7326945},
  abstract = {Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition, which can be consider as a classification task. Most of the existing studies and research efforts are following the conventional pattern recognition paradigm, which is based on the construction of complex handcrafted features. However, it is rarely known which features are important for the problem at hand. In contrast to these approaches, we propose a deep learning based classification method that hierarchically constructs high-level features in an automated way. Our method exploits a Convolutional Neural Network to encode pixels' spectral and spatial information and a Multi-Layer Perceptron to conduct the classification task. Experimental results and quantitative validation on widely used datasets showcasing the potential of the developed approach for accurate hyperspectral data classification.},
  booktitle = {Geoscience and {{Remote Sensing Symposium}} ({{IGARSS}}), 2015 {{IEEE International}}},
  author = {Makantasis, Konstantinos and Karantzalos, Konstantinos and Doulamis, Anastasios and Doulamis, Nikolaos},
  month = jul,
  year = {2015},
  keywords = {Accuracy,complex handcrafted construction,conventional pattern recognition paradigm,convolutional neural networks,deep learning based classification method,deep supervised learning,Earth observation,geophysical techniques,hyperspectral data classification,hyperspectral imaging,image classification,Imaging spectroscopy,Machine learning,narrow spectral bands,neural nets,Neural networks,object recognition,spectral observation,support vector machines,Training},
  pages = {4959-4962},
  file = {/home/naudeber/Bibliographie//undefined/2015/Makantasis et al 2015 - Deep supervised learning for hyperspectral data classification through.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/UZABFHNJ/abs_all.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/WXK4X9RP/7326945.html}
}

@article{deschamps_atmospheric_1980,
  title = {Atmospheric Correction of Infrared Measurements of Sea Surface Temperature Using Channels at 3.7, 11 and 12 {{$M$m}}},
  volume = {18},
  issn = {0006-8314, 1573-1472},
  doi = {10.1007/BF00121320},
  abstract = {Atmospheric effects upon the radiometric determination of surface temperature were studied for channels centered at 3.7, 11 and 12 $M$m. The error due to the atmosphere is least for the channel centered at 3.7 $M$m, which is a real advantage. The use of a linear combination of two or all three of these channels allows one to eliminate most of the atmospheric effect. If instrumental noise of from 0.1 to 0.2 K is accounted for in each channel, the best results are obtained by a combination of the two channels at 3.7 and 12 $M$m.},
  language = {en},
  number = {2},
  journal = {Boundary-Layer Meteorology},
  author = {Deschamps, P. Y. and Phulpin, T.},
  month = mar,
  year = {1980},
  pages = {131-143},
  file = {/home/naudeber/Bibliographie//Boundary-Layer Meteorology/1980/Deschamps Phulpin 1980 - Atmospheric correction of infrared measurements of sea surface temperature.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/NQZRDHV5/BF00121320.html}
}

@article{chavez_image-based_1996,
  title = {Image-Based Atmospheric Corrections: {{Revisited}} and Improved},
  volume = {62},
  shorttitle = {Image-Based Atmospheric Corrections},
  number = {9},
  journal = {Photogrammetric engineering and remote sensing},
  author = {Chavez, PS},
  year = {1996},
  pages = {1025--1036},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/DPGI2CCN/cat.inist.fr.html}
}

@inproceedings{slavkovikj_hyperspectral_2015,
  title = {Hyperspectral {{Image Classification}} with {{Convolutional Neural Networks}}},
  isbn = {978-1-4503-3459-4},
  doi = {10.1145/2733373.2806306},
  language = {en},
  publisher = {{ACM Press}},
  author = {Slavkovikj, Viktor and Verstockt, Steven and De Neve, Wesley and Van Hoecke, Sofie and {Van de Walle}, Rik},
  year = {2015},
  keywords = {classification,convolutional neural networks,deep learning,hyperspectral imaging},
  pages = {1159-1162},
  file = {/home/naudeber/Bibliographie//ACM Press/2015/Slavkovikj et al 2015 - Hyperspectral Image Classification with Convolutional Neural Networks.pdf;/home/naudeber/Bibliographie//ACM/2015/Slavkovikj et al 2015 - Hyperspectral Image Classification with Convolutional Neural Networks.pdf}
}

@article{rahman_smac_1994,
  title = {{{SMAC}}: A Simplified Method for the Atmospheric Correction of Satellite Measurements in the Solar Spectrum},
  volume = {15},
  issn = {0143-1161},
  shorttitle = {{{SMAC}}},
  doi = {10.1080/01431169408954055},
  abstract = {This paper describes a computationally fast and accurate technique for the atmospheric correction of satellite measurements in the solar spectrum. The main advantage of the method is that it is several hundred times faster than more detailed radiative transfer models like 5S and that it does not require precalculated look-up tables. The method is especially useful for correcting the huge amounts of data acquired by large-field-of-view high-repetitivity sensors, like the ones on board polar orbiting and geostationary meteorological satellites. The technique is based on a set of equations with coefficients which depend on the spectral band of the sensor. Semi-empirical formulations are used to describe the different interactions (absorption, scattering, etc.) of solar radiation with atmospheric constituents during its traverse through the atmosphere. Sensor specific coefficients of each equation are determined using a best fit technique against the computations of the 5S code (Simulation of Satellite Signal in the Solar Spectrum, Tanr{\'e} et al. 1990). Other radiative transfer models could be used. Once coefficients for a specific spectral band are determined, the inputs of the model are vertically integrated gaseous contents, aerosol optical depth at 550 nm, geometric conditions and reflectance at the top of the atmosphere (TOA). TOA reflectances were calculated using our method and then compared to the TOA reflectances calculated by 5S for a wide range of gaseous and aerosol contents, illumination and observation conditions for various sensor spectral bands. In the case of NOAA-9 AVHRR visible data the maximum relative error is 2$\cdot$35 per cent (i.e. 0$\cdot$01 for a reflectance value of 0$\cdot$4) and the corresponding rmse is 0$\cdot$0018. For NOAA-9 AVHRR near-infrared, Meteosat-1 visible, Landsat-5 TM band 1 and Landsat-5 TM band 4 the maximum relative errors are 3$\cdot$11, 4$\cdot$0, 1$\cdot$65 and 2$\cdot$37per cent respectively. The corresponding values of the rmse are 0$\cdot$0022, 0$\cdot$0015, 0$\cdot$0017 and 0$\cdot$0012. The method can be used both in the direct and in the inverse mode, i.e., to compute TOA reflectance knowing the surface reflectance (e.g., for fast sensitivity studies), or conversely to retrieve surface reflectance from the TOA reflectance. It can easily be implemented in operational data preprocessing computer code, since only band specific coefficients need to be updated when new sensors are flown, while the routines remain the same.},
  number = {1},
  journal = {International Journal of Remote Sensing},
  author = {Rahman, H. and Dedieu, G.},
  month = jan,
  year = {1994},
  pages = {123-143},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/4HFRGDS7/01431169408954055.html}
}

@article{fabre_estimation_2015,
  title = {Estimation of {{Soil Moisture Content}} from the {{Spectral Reflectance}} of {{Bare Soils}} in the 0.4\textendash{}2.5 $M$m {{Domain}}},
  volume = {15},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  doi = {10.3390/s150203262},
  abstract = {This work aims to compare the performance of new methods to estimate the Soil Moisture Content (SMC) of bare soils from their spectral signatures in the reflective domain (0.4\textendash{}2.5 $\mathrm{\mu}$m) in comparison with widely used spectral indices like Normalized Soil Moisture Index (NSMI) and Water Index SOIL (WISOIL). Indeed, these reference spectral indices use wavelengths located in the water vapour absorption bands and their performance are thus very sensitive to the quality of the atmospheric compensation. To reduce these limitations, two new spectral indices are proposed which wavelengths are defined using the determination matrix tool by taking into account the atmospheric transmission: Normalized Index of Nswir domain for Smc estimatiOn from Linear correlation (NINSOL) and Normalized Index of Nswir domain for Smc estimatiOn from Non linear correlation (NINSON). These spectral indices are completed by two new methods based on the global shape of the soil spectral signatures. These methods are the Inverse Soil semi-Empirical Reflectance model (ISER), using the inversion of an existing empirical soil model simulating the soil spectral reflectance according to soil moisture content for a given soil class, and the convex envelope model, linking the area between the envelope and the spectral signature to the SMC. All these methods are compared using a reference database built with 32 soil samples and composed of 190 spectral signatures with five or six soil moisture contents. Half of the database is used for the calibration stage and the remaining to evaluate the performance of the SMC estimation methods. The results show that the four new methods lead to similar or better performance than the one obtained by the reference indices. The RMSE is ranging from 3.8\% to 6.2\% and the coefficient of determination R2 varies between 0.74 and 0.91 with the best performance obtained with the ISER model. In a second step, simulated spectral radiances at the sensor level are used to analyse the sensitivity of these methods to the sensor spectral resolution and the water vapour content knowledge. The spectral signatures of the database are then used to simulate the signal at the top of atmosphere with a radiative transfer model and to compute the integrated incident signal representing the spectral radiance measurements of the HYMAP airborne hyperspectral instrument. The sensor radiances are then corrected from the atmosphere by an atmospheric compensation tool to retrieve the surface reflectances. The SMC estimation methods are then applied on the retrieve spectral reflectances. The adaptation of the spectral index wavelengths to the HyMap sensor spectral bands and the application of the convex envelope and ISER models to boarder spectral bands lead to an error on the SMC estimation. The best performance is then obtained with the ISER model (RMSE of 2.9\% and R2 of 0.96) while the four other methods lead to quite similar RMSE (from 6.4\% to 7.8\%) and R$^2$ (between 0.79 and 0.83) values. In the atmosphere compensation processing, an error on the water vapour content is introduced. The most robust methods to water vapour content variations are WISOIL, NINSON, NINSOL and ISER model. The convex envelope model and NSMI index require an accurate estimation of the water vapour content in the atmosphere.},
  language = {en},
  number = {2},
  journal = {Sensors},
  author = {Fabre, Sophie and Briottet, Xavier and Lesaignoux, Audrey},
  month = feb,
  year = {2015},
  keywords = {bare soil,soil model,soil moisture content,spectral indices,spectral reflectance},
  pages = {3262-3281},
  file = {/home/naudeber/Bibliographie//Sensors/2015/Fabre et al 2015 - Estimation of Soil Moisture Content from the Spectral Reflectance of Bare Soils.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/RJKKUUUK/3262.html}
}

@article{cubero-castan_physics-based_2015,
  title = {A {{Physics}}-{{Based Unmixing Method}} to {{Estimate Subpixel Temperatures}} on {{Mixed Pixels}}},
  volume = {53},
  issn = {0196-2892},
  doi = {10.1109/TGRS.2014.2350771},
  abstract = {This paper presents a new algorithm for the analysis of linear spectral mixtures in the thermal infrared domain, with the goal to jointly estimate the abundance and the subpixel temperature in a mixed pixel, i.e., to estimate the relative proportion and the temperature of each material composing the mixed pixel. This novel approach is a two-step procedure. First, it estimates the emissivity and the temperature over pure pixels using the standard temperature and emissivity separation (TES) algorithm. Second, it estimates the abundance and the subpixel temperature using a new unmixing physics-based model, called Thermal Remote sensing Unmixing for Subpixel Temperature (TRUST). This model is based on an estimator of the subpixel temperature obtained by linearizing the black body law around the mean temperature of each material. The abundance is then retrieved by minimizing the reconstruction error with the estimation of the subpixel temperatures. The TRUST method is benchmarked on simulated scenes against the fully constrained least squares unmixing applied on the radiance and on the estimation of surface emissivity using the TES algorithm. The TRUST method shows better results on pure and mixed pixels composed of two materials. TRUST also shows promising results when applied on thermal hyperspectral data acquired with the Thermal Airborne Spectrographic Imager during the Detection in Urban scenario using Combined Airborne imaging Sensors campaign and estimates coherent localization of mixed-pixel areas.},
  number = {4},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {{Cubero-Castan}, M. and Chanussot, J. and Achard, V. and Briottet, X. and Shimoni, M.},
  month = apr,
  year = {2015},
  keywords = {black body law,DUCAS campaign,emissivity,Estimation,fully constrained least squares unmixing,geophysical signal processing,hyperspectral imaging,linear spectral mixtures,linear unmixing,Materials,mixed pixel,physics based unmixing method,radiance,reconstruction error,regression analysis,remote sensing,subpixel temperature estimation,surface emissivity,temperature and emissivity separation (TES),Temperature sensors,temperature-emissivity separation algorithm,TES algorithm,Thermal Airborne Spectrographic Imager (TASI),Thermal Airborne Spectrographic Imager data,thermal hyperspectral data,thermal infrared domain,thermal infrared sensors,Thermal Remote sensing Unmixing for Subpixel Temperature,TRUST method},
  pages = {1894-1906},
  file = {/home/naudeber/Bibliographie//IEEE Transactions on Geoscience and Remote Sensing/2015/Cubero-Castan et al 2015 - A Physics-Based Unmixing Method to Estimate Subpixel Temperatures on Mixed.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/4Z9FC55U/6898859.html}
}

@article{rodarmel_principal_2002,
  title = {Principal Component Analysis for Hyperspectral Image Classification},
  volume = {62},
  number = {2},
  journal = {Surveying and Land Information Science},
  author = {Rodarmel, Craig and Shan, Jie},
  year = {2002},
  pages = {115},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/AUGEGC3B/AuthErrorPage.html}
}

@article{dellacqua_exploiting_2004,
  title = {Exploiting Spectral and Spatial Information in Hyperspectral Urban Data with High Resolution},
  volume = {1},
  issn = {1545-598X},
  doi = {10.1109/LGRS.2004.837009},
  abstract = {Very high resolution hyperspectral data should be very useful to provide detailed maps of urban land cover. In order to provide such maps, both accurate and precise classification tools need, however, to be developed. In this letter, new methods for classification of hyperspectral remote sensing data are investigated, with the primary focus on multiple classifications and spatial analysis to improve mapping accuracy in urban areas. In particular, we compare spatial reclassification and mathematical morphology approaches. We show results for classification of DAIS data over the town of Pavia, in northern Italy. Classification maps of two test areas are given, and the overall and individual class accuracies are analyzed with respect to the parameters of the proposed classification procedures.},
  number = {4},
  journal = {IEEE Geoscience and Remote Sensing Letters},
  author = {Dell'Acqua, F. and Gamba, P. and Ferrari, A. and Palmason, J. A. and Benediktsson, J. A. and Arnason, K.},
  month = oct,
  year = {2004},
  keywords = {DAIS data,Detectors,high resolution hyperspectral urban data,hyperspectral imaging,hyperspectral remote sensing,Hyperspectral sensors,image morphing,Image recognition,Image resolution,Infrared imaging,Infrared spectra,Mathematical morphology,Morphology,multiclassification,northern Italy,Optical imaging,Pavia,remote sensing,spatial analysis,spatial information,spatial reclassification,Spatial resolution,Spectral analysis,spectral information,terrain mapping,Urban areas,urban remote sensing},
  pages = {322-326},
  file = {/home/naudeber/Bibliographie//IEEE Geoscience and Remote Sensing Letters/2004/Dell'Acqua et al 2004 - Exploiting spectral and spatial information in hyperspectral urban data with.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/MXEJTA6P/1347132.html}
}

@article{plaza_spatial/spectral_2002,
  title = {Spatial/Spectral Endmember Extraction by Multidimensional Morphological Operations},
  volume = {40},
  issn = {0196-2892},
  doi = {10.1109/TGRS.2002.802494},
  abstract = {Spectral mixture analysis provides an efficient mechanism for the interpretation and classification of remotely sensed multidimensional imagery. It aims to identify a set of reference signatures (also known as endmembers) that can be used to model the reflectance spectrum at each pixel of the original image. Thus, the modeling is carried out as a linear combination of a finite number of ground components. Although spectral mixture models have proved to be appropriate for the purpose of large hyperspectral dataset subpixel analysis, few methods are available in the literature for the extraction of appropriate endmembers in spectral unmixing. Most approaches have been designed from a spectroscopic viewpoint and, thus, tend to neglect the existing spatial correlation between pixels. This paper presents a new automated method that performs unsupervised pixel purity determination and endmember extraction from multidimensional datasets; this is achieved by using both spatial and spectral information in a combined manner. The method is based on mathematical morphology, a classic image processing technique that can be applied to the spectral domain while being able to keep its spatial characteristics. The proposed methodology is evaluated through a specifically designed framework that uses both simulated and real hyperspectral data.},
  number = {9},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Plaza, A. and Martinez, P. and Perez, R. and Plaza, J.},
  month = sep,
  year = {2002},
  keywords = {classification,data analysis,endmember extraction,feature extraction,geophysical signal processing,ground components,hyperspectral imaging,Hyperspectral sensors,image analysis,image classification,image processing technique,interpretation,Mathematical morphology,Morphological operations,multidimensional morphological operations,Multidimensional systems,Pixel,reference signatures,reflectance spectrum,Reflectivity,remote sensing,remotely sensed multidimensional imagery,spatial correlation,spatial information,spatial/spectral endmember extraction,Spectral analysis,spectral domain,spectral information,spectral mixture analysis,spectral unmixing,spectral-domain analysis,Spectroscopy,unsupervised pixel purity determination},
  pages = {2025-2041},
  file = {/home/naudeber/Bibliographie//IEEE Transactions on Geoscience and Remote Sensing/2002/Plaza et al 2002 - Spatial-spectral endmember extraction by multidimensional morphological.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/3T87SAJU/1046852.html}
}

@article{tarabalka_spectralspatial_2009,
  title = {Spectral\textendash{}spatial Classification of Hyperspectral Imagery Based on Partitional Clustering Techniques},
  volume = {47},
  number = {8},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Tarabalka, Yuliya and Benediktsson, J{\'o}n Atli and Chanussot, Jocelyn},
  year = {2009},
  pages = {2973--2987},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/X8EDNZHU/4840429.html}
}

@article{tarabalka_segmentation_2010,
  title = {Segmentation and Classification of Hyperspectral Images Using Watershed Transformation},
  volume = {43},
  number = {7},
  journal = {Pattern Recognition},
  author = {Tarabalka, Yuliya and Chanussot, Jocelyn and Benediktsson, Jon Atli},
  year = {2010},
  pages = {2367--2379},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/RQEVANGZ/S003132031000049X.html}
}

@article{tuia_domain_2016,
  title = {Domain {{Adaptation}} for the {{Classification}} of {{Remote Sensing Data}}: {{An Overview}} of {{Recent Advances}}},
  volume = {4},
  issn = {2168-6831},
  shorttitle = {Domain {{Adaptation}} for the {{Classification}} of {{Remote Sensing Data}}},
  doi = {10.1109/MGRS.2016.2548504},
  number = {2},
  journal = {IEEE Geoscience and Remote Sensing Magazine},
  author = {Tuia, Devis and Persello, Claudio and Bruzzone, Lorenzo},
  month = jun,
  year = {2016},
  pages = {41-57}
}

@article{camps-valls_composite_2006,
  title = {Composite Kernels for Hyperspectral Image Classification},
  volume = {3},
  number = {1},
  journal = {IEEE Geoscience and Remote Sensing Letters},
  author = {{Camps-Valls}, Gustavo and {Gomez-Chova}, Luis and {Mu{\~n}oz-Mar{\'\i}}, Jordi and {Vila-Franc{\'e}s}, Joan and {Calpe-Maravilla}, Javier},
  year = {2006},
  pages = {93--97},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/J4TFEMFQ/1576697.html}
}

@inproceedings{he_delving_2015,
  title = {Delving {{Deep}} into {{Rectifiers}}: {{Surpassing Human}}-{{Level Performance}} on {{ImageNet Classification}}},
  shorttitle = {Delving {{Deep}} into {{Rectifiers}}},
  doi = {10.1109/ICCV.2015.123},
  abstract = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94\% top-5 test error on the ImageNet 2012 classification dataset. This is a 26\% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66\% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1\%, [26]) on this dataset.},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  month = dec,
  year = {2015},
  keywords = {Adaptation models,Biological neural networks,Computational modeling,Gaussian distribution,human-level performance,ILSVRC 2014 winner,image classification,ImageNet 2012 classification dataset,ImageNet classification,model fitting,network architectures,neural nets,overfitting risk,parametric rectified linear unit,PReLU,rectified activation units,rectifier neural networks,rectifier nonlinearities,robust initialization method,state-of-the-art neural networks,Testing,Training},
  pages = {1026-1034},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/NXDQWID9/7410480.html}
}

@inproceedings{parra_unmixing_1999,
  title = {Unmixing Hyperspectral Data},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Neural Information Processing Systems}}},
  publisher = {{MIT Press}},
  author = {Parra, Lucas and Spence, Clay and Sajda, Paul and Ziehe, Andreas and M{\"u}ller, Klaus-Robert},
  year = {1999},
  pages = {942--948},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/2D4V6RM2/citation.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/9K6R3BS8/citation.html}
}

@article{damodaran_sparse_2017,
  title = {Sparse {{Hilbert Schmidt Independence Criterion}} and {{Surrogate}}-{{Kernel}}-{{Based Feature Selection}} for {{Hyperspectral Image Classification}}},
  volume = {55},
  number = {4},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Damodaran, Bharath Bhushan and Courty, Nicolas and Lef{\`e}vre, S{\'e}bastien},
  year = {2017},
  pages = {2385--2398},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/TUC6NBUH/Damodaran et al_2017_Sparse Hilbert Schmidt Independence Criterion and Surrogate-Kernel-Based.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/8JZQDHPS/7828042.html}
}

@article{goel_classification_2003,
  title = {Classification of Hyperspectral Data by Decision Trees and Artificial Neural Networks to Identify Weed Stress and Nitrogen Status of Corn},
  volume = {39},
  issn = {0168-1699},
  doi = {10.1016/S0168-1699(03)00020-6},
  abstract = {This study evaluates the potential of decision tree classification algorithms for the classification of hyperspectral data, with the goal of discriminating between different growth scenarios in a cornfield. A comparison was also made between decision tree and artificial neural networks (ANNs) classification accuracies. In the summer of the year 2000, a two-factor field experiment representing different crop conditions was carried out. Corn was grown under four weed management strategies: no weed control, control of grasses, control of broadleaf weeds, and full weed control with nitrogen levels of 60, 120, and 250 N kg/ha. Hyperspectral data using a Compact Airborne Spectrographic Imager were acquired three times during the entire growing season. Decision tree technology was applied to classify different treatments based on the hyperspectral data. Various tree-growing mechanisms were used to improve the accuracy of classification. Misclassification rates of detecting all the combinations of different nitrogen and weed categories were 43, 32, and 40\% for hyperspectral data sets obtained at the initial growth, the tasseling and the full maturity stages, respectively. However, satisfactory classification results were obtained when one factor (nitrogen or weed) was considered at a time. In this case, misclassification rates were only 22 and 18\% for nitrogen and weeds, respectively, for the data obtained at the tasseling stage. Slightly better results were obtained by following the ANN approach. However, the advantage with the decision tree was the formulation of simple and clear classification rules. The highest accuracy was obtained for the data acquired at tasseling stage. The results indicate the potential of decision tree classification algorithms and ANN usage in the classification of hyperspectral data for crop condition assessment.},
  number = {2},
  journal = {Computers and Electronics in Agriculture},
  author = {Goel, P. K and Prasher, S. O and Patel, R. M and Landry, J. A and Bonnell, R. B and Viau, A. A},
  month = may,
  year = {2003},
  keywords = {Artificial neural networks,classification,Classification,Corn,Decision tree,Hyperspectral,Nitrogen,remote sensing,Remote sensing,Weeds},
  pages = {67-93},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/R8QTFWNE/S0168169903000206.html}
}

@inproceedings{fu_semi-supervised_2016,
  title = {Semi-Supervised Classification of Hyperspectral Imagery Based on Stacked Autoencoders},
  volume = {10033},
  doi = {10.1117/12.2245011},
  abstract = {Hyperspectral imagery has high spectral resolution, and spectrum of it has always been non-linear. The traditional classification methods cannot get better result when the number of samples is small. Combined with the theory of deep learning, a new semi-supervised method based on stacked autoencoders (SAE) is proposed for hyperspectral imagery classification. Firstly, with stacked autoencoders, a deep network model is constructed. Then, unsupervised pre-training is carried combined SOFTMAX classifier with unlabeled samples. Finally, fine-tuning the network model with small labeled samples, the SAE-based classifier can be got to learn implicit feature of spectrum of hyperspectral imagery and achieve classification of hyperspectral imagery. According to comparative experiments, the results indicate that the proposed method is effective to improve the hyperspectral imagery classification accuracy in case of small samples.},
  author = {Fu, Qiongying and Yu, Xuchu and Wei, Xiangpo and Xue, Zhixiang},
  year = {2016},
  pages = {100332B-100332B-5},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/I9A32UWW/Fu et al_2016_Semi-supervised classification of hyperspectral imagery based on stacked.pdf}
}

@article{xing_stacked_2015,
  title = {Stacked {{Denoise Autoencoder Based Feature Extraction}} and {{Classification}} for {{Hyperspectral Images}}},
  volume = {2016},
  issn = {1687-725X},
  doi = {10.1155/2016/3632943},
  abstract = {Deep learning methods have been successfully applied to learn feature representations for high-dimensional data, where the learned features are able to reveal the nonlinear properties exhibited in the data. In this paper, deep learning method is exploited for feature extraction of hyperspectral data, and the extracted features can provide good discriminability for classification task. Training a deep network for feature extraction and classification includes unsupervised pretraining and supervised fine-tuning. We utilized stacked denoise autoencoder (SDAE) method to pretrain the network, which is robust to noise. In the top layer of the network, logistic regression (LR) approach is utilized to perform supervised fine-tuning and classification. Since sparsity of features might improve the separation capability, we utilized rectified linear unit (ReLU) as activation function in SDAE to extract high level and sparse features. Experimental results using Hyperion, AVIRIS, and ROSIS hyperspectral data demonstrated that the SDAE pretraining in conjunction with the LR fine-tuning and classification (SDAE\_LR) can achieve higher accuracies than the popular support vector machine (SVM) classifier.},
  language = {en},
  journal = {Journal of Sensors},
  author = {Xing, Chen and Ma, Li and Yang, Xiaoquan},
  month = nov,
  year = {2015},
  pages = {e3632943},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/CHRQKA3G/3632943.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/EN4TADTC/Xing et al_2015_Stacked Denoise Autoencoder Based Feature Extraction and Classification for.pdf}
}

@article{fauvel_spatial-spectral_2012,
  title = {A {{Spatial}}-Spectral {{Kernel}}-Based {{Approach}} for the {{Classification}} of {{Remote}}-Sensing {{Images}}},
  volume = {45},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2011.03.035},
  abstract = {Classification of remotely sensed images with very high spatial resolution is investigated. The proposed method deals with the joint use of the spatial and the spectral information provided by the remote-sensing images. A definition of an adaptive neighborhood system is considered. Based on morphological area filtering, the spatial information associated with each pixel is modeled as the set of connected pixels with an identical gray value (flat zone) to which the pixel belongs: The pixel's neighborhood is characterized by the vector median value of the corresponding flat zone. The spectral information is the original pixel's value, be it a scalar or a vector value. Using kernel methods, the spatial and spectral information are jointly used for the classification through a support vector machine formulation. Experiments on hyperspectral and panchromatic images are presented and show a significant increase in classification accuracies for peri-urban area: For instance, with the first data set, the overall accuracy is increased from 80\% with a conventional support vectors machines classifier to 86\% with the proposed approach. Comparisons with other contextual methods show that the method is competitive.},
  number = {1},
  journal = {Pattern Recogn.},
  author = {Fauvel, M. and Chanussot, J. and Benediktsson, J. A.},
  month = jan,
  year = {2012},
  keywords = {Adaptive neighborhood,Area filtering,Composite kernel,Hyperspectral remote-sensing images,Mathematical morphology,Support vectors machines,Urban area},
  pages = {381--392},
  file = {/home/naudeber/Bibliographie//Pattern Recognition/2012/Fauvel et al 2012 - A spatial–spectral kernel-based approach for the classification of.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/AA7VWCSN/S0031320311002019.html}
}

@article{fauvel_advances_2013,
  title = {Advances in {{Spectral}}-{{Spatial Classification}} of {{Hyperspectral Images}}},
  volume = {101},
  issn = {0018-9219},
  doi = {10.1109/JPROC.2012.2197589},
  abstract = {Recent advances in spectral-spatial classification of hyperspectral images are presented in this paper. Several techniques are investigated for combining both spatial and spectral information. Spatial information is extracted at the object (set of pixels) level rather than at the conventional pixel level. Mathematical morphology is first used to derive the morphological profile of the image, which includes characteristics about the size, orientation, and contrast of the spatial structures present in the image. Then, the morphological neighborhood is defined and used to derive additional features for classification. Classification is performed with support vector machines (SVMs) using the available spectral information and the extracted spatial information. Spatial postprocessing is next investigated to build more homogeneous and spatially consistent thematic maps. To that end, three presegmentation techniques are applied to define regions that are used to regularize the preliminary pixel-wise thematic map. Finally, a multiple-classifier (MC) system is defined to produce relevant markers that are exploited to segment the hyperspectral image with the minimum spanning forest algorithm. Experimental results conducted on three real hyperspectral images with different spatial and spectral resolutions and corresponding to various contexts are presented. They highlight the importance of spectral-spatial strategies for the accurate classification of hyperspectral images and validate the proposed methods.},
  number = {3},
  journal = {Proceedings of the IEEE},
  author = {Fauvel, Mathieu and Tarabalka, Yuliya and Benediktsson, J{\'o}n Atli and Chanussot, Jocelyn and Tilton, James C.},
  month = mar,
  year = {2013},
  keywords = {classification,Classification algorithms,conventional pixel level,feature extraction,geophysical image processing,homogeneous thematic maps,hyperspectral image,hyperspectral image segment,hyperspectral imaging,image classification,image morphological profile,Image resolution,image segmentation,Kernel,kernel methods,Mathematical morphology,morphological neighborhood,multiple-classifier system,Nearest neighbor searches,object level,pixel-wise thematic map,presegmentation techniques,remote sensing,segmentation,spanning forest algorithm,spatial information,spatial postprocessing,Spatial resolution,spatial structure contrast,spatial structure orientation,spatial structure size,spatially consistent thematic maps,Spectral analysis,spectral information,spectral-spatial classification,spectral–spatial classifier,support vector machines,vegetation mapping},
  pages = {652-675},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/8XPE5X8G/Fauvel et al_2013_Advances in Spectral-Spatial Classification of Hyperspectral Images.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/D7SGGI9Z/6297992.html}
}

@inproceedings{wu_semi-supervised_2016,
  title = {Semi-Supervised {{Conditional Random Field}} for Hyperspectral Remote Sensing Image Classification},
  doi = {10.1109/IGARSS.2016.7729675},
  abstract = {Conditional Random Field(CRF) has been successfully applied to the hyperspectral image classification. However, it suffers from the availability of large amount of labeled pixels, which is labor- and time-consuming to obtain in practice. In this paper, a semi-supervised CRF(ssCRF) is proposed for hyperspectral image classification with limited labeled pixels. Laplacian Support Vector Machine(LapSVM), after extended into the composite kernel type, is defined as the association potential. And the Potts model is utilized as the interaction potential. The ssCRF is evaluated on the two benchmarks and the results show the effectiveness of ssCRF.},
  booktitle = {2016 {{IEEE International Geoscience}} and {{Remote Sensing Symposium}} ({{IGARSS}})},
  author = {Wu, J. and Jiang, Z. and Zhang, H. and Cai, B. and Wei, Q.},
  month = jul,
  year = {2016},
  keywords = {classification,composite kernel type,CRF,Hyperspectral,hyperspectral image classification,hyperspectral imaging,hyperspectral remote sensing,image classification,Kernel,labeled pixel,Laplacian SVM,Potts model,remote sensing,semi-supervised,semisupervised conditional random field,ssCRF effectiveness,support vector machine,support vector machines,Training},
  pages = {2614-2617},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/ZZPCMZEE/7729675.html}
}

@article{zhao_combining_2015,
  title = {On Combining Multiscale Deep Learning Features for the Classification of Hyperspectral Remote Sensing Imagery},
  volume = {36},
  issn = {0143-1161},
  doi = {10.1080/2150704X.2015.1062157},
  abstract = {In recent years, satellite imagery has greatly improved in both spatial and spectral resolution. One of the major unsolved problems in highly developed remote sensing imagery is the manual selection and combination of appropriate features according to spectral and spatial properties. Deep learning framework can learn global and robust features from the training data set automatically, and it has achieved state-of-the-art classification accuracies over different image classification tasks. In this study, a technique is proposed which attempts to classify hyperspectral imagery by incorporating deep learning features. Firstly, deep learning features are extracted by multiscale convolutional auto-encoder. Then, based on the learned deep learning features, a logistic regression classifier is trained for classification. Finally, parameters of deep learning framework are analysed and the potential development is introduced. Experiments are conducted on the well-known Pavia data set which is acquired by the reflective optics system imaging spectrometer sensor. It is found that the deep learning-based method provides a more accurate classification result than the traditional ones.},
  number = {13},
  journal = {International Journal of Remote Sensing},
  author = {Zhao, Wenzhi and Guo, Zhou and Yue, Jun and Zhang, Xiuyuan and Luo, Liqun},
  month = jul,
  year = {2015},
  pages = {3368-3379},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/BUC3UFZN/2150704X.2015.html}
}

@article{zhao_spectral-spatial_2016,
  title = {Spectral-{{Spatial Feature Extraction}} for {{Hyperspectral Image Classification}}: {{A Dimension Reduction}} and {{Deep Learning Approach}}},
  volume = {54},
  issn = {0196-2892},
  shorttitle = {Spectral \#x2013;{{Spatial Feature Extraction}} for {{Hyperspectral Image Classification}}},
  doi = {10.1109/TGRS.2016.2543748},
  abstract = {In this paper, we propose a spectral-spatial feature based classification (SSFC) framework that jointly uses dimension reduction and deep learning techniques for spectral and spatial feature extraction, respectively. In this framework, a balanced local discriminant embedding algorithm is proposed for spectral feature extraction from high-dimensional hyperspectral data sets. In the meantime, convolutional neural network is utilized to automatically find spatial-related features at high levels. Then, the fusion feature is extracted by stacking spectral and spatial features together. Finally, the multiple-feature-based classifier is trained for image classification. Experimental results on well-known hyperspectral data sets show that the proposed SSFC method outperforms other commonly used methods for hyperspectral image classification.},
  number = {8},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Zhao, W. and Du, S.},
  month = aug,
  year = {2016},
  keywords = {Algorithm design and analysis,Balanced local discriminant embedding (BLDE),balanced local discriminant embedding algorithm,convolutional neural network,convolutional neural network (CNN),deep learning (DL),deep learning approach,deep learning techniques,dimension reduction (DR),dimension reduction approach,feature extraction,fusion feature,high-dimensional hyperspectral data sets,hyperspectral image classification,hyperspectral imaging,image classification,Machine learning,spectral-spatial feature based classification framework,spectral-spatial feature extraction,SSFC framework,Training},
  pages = {4544-4554},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/68FM8897/7450160.html}
}

@article{yue_spectral-spatial_2015,
  title = {Spectral-Spatial Classification of Hyperspectral Images Using Deep Convolutional Neural Networks},
  volume = {6},
  issn = {2150-704X},
  doi = {10.1080/2150704X.2015.1047045},
  abstract = {In this letter, a novel deep learning framework for hyperspectral image classification using both spectral and spatial features is presented. The framework is a hybrid of principal component analysis, deep convolutional neural networks (DCNNs) and logistic regression (LR). The DCNNs for hierarchically extract deep features is introduced into hyperspectral image classification for the first time. The proposed technique consists of two steps. First, feature map generation algorithm is presented to generate the spectral and spatial feature maps. Second, the DCNNs-LR classifier is trained to get useful high-level features and to fine-tune the whole model. Comparative experiments conducted over widely used hyperspectral data indicate that DCNNs-LR classifier built in this proposed deep learning framework provides better classification accuracy than previous hyperspectral classification methods.},
  number = {6},
  journal = {Remote Sensing Letters},
  author = {Yue, Jun and Zhao, Wenzhi and Mao, Shanjun and Liu, Hui},
  month = jun,
  year = {2015},
  pages = {468-477},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/BMTX2UDC/2150704X.2015.html}
}

@article{wang_spectralspatial_2017,
  title = {Spectral\textendash{}spatial Multi-Feature-Based Deep Learning for Hyperspectral Remote Sensing Image Classification},
  volume = {21},
  issn = {1432-7643, 1433-7479},
  doi = {10.1007/s00500-016-2246-3},
  abstract = {Hyperspectral remote sensing has a strong ability in information expression, so it provides better support for classification. The methods proposed to deal the hyperspectral data classification problems were build one by one. However, most of them committed to spectral feature extraction that means wasting some valuable information and poor classification results. Thus, we should pay more attention to multi-features. And on the other hand, due to extreme requirements for classification accuracy, we should hierarchically explore more deep features. The first thought is machine learning, but the traditional machine learning classifiers, like the support vector machine, are not friendly to larger inputs and features. This paper introduces a hybrid of principle component analysis (PCA), guided filtering, deep learning architecture into hyperspectral data classification. In detail, as a mature dimension reduction architecture, PCA is capable of reducing the redundancy of hyperspectral information. In addition, guided filtering provides a passage to spatial-dominated information concisely and effectively. According to the stacked autoencoders which is a efficient deep learning architecture, deep-level multi-features are not in mystery. Two public data set PaviaU and Salinas are used to test the proposed algorithm. Experimental results demonstrate that the proposed spectral\textendash{}spatial hyperspectral image classification method can show competitive performance. Multi-feature learning based on deep learning exhibits a great potential on the classification of hyperspectral images. When the number of samples is 30 \% and the iteration number is over 1000, the accuracy rates for both of the two data set are over 99 \%.},
  language = {en},
  number = {1},
  journal = {Soft Computing},
  author = {Wang, Lizhe and Zhang, Jiabin and Liu, Peng and Choo, Kim-Kwang Raymond and Huang, Fang},
  month = jan,
  year = {2017},
  pages = {213-221},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/SZXIGRAB/Wang et al_2017_Spectral–spatial multi-feature-based deep learning for hyperspectral remote.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/IJKBXHXK/s00500-016-2246-3.html}
}

@article{ratle_semisupervised_2010,
  title = {Semisupervised {{Neural Networks}} for {{Efficient Hyperspectral Image Classification}}},
  volume = {48},
  issn = {0196-2892},
  doi = {10.1109/TGRS.2009.2037898},
  abstract = {A framework for semisupervised remote sensing image classification based on neural networks is presented. The methodology consists of adding a flexible embedding regularizer to the loss function used for training neural networks. Training is done using stochastic gradient descent with additional balancing constraints to avoid falling into local minima. The method constitutes a generalization of both supervised and unsupervised methods and can handle millions of unlabeled samples. Therefore, the proposed approach gives rise to an operational classifier, as opposed to previously presented transductive or Laplacian support vector machines (TSVM or LapSVM, respectively). The proposed methodology constitutes a general framework for building computationally efficient semisupervised methods. The method is compared with LapSVM and TSVM in semisupervised scenarios, to SVM in supervised settings, and to online and batch k-means for unsupervised learning. Results demonstrate the improved classification accuracy and scalability of this approach on several hyperspectral image classification problems.},
  number = {5},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Ratle, F. and {Camps-Valls}, G. and Weston, J.},
  month = may,
  year = {2010},
  keywords = {geophysical image processing,geophysical techniques,graph Laplacian,hyperspectral image classification,hyperspectral imaging,Hyperspectral sensors,image classification,Laplace equations,Laplacian support vector machine (LapSVM),Laplacian support vector machines,learning (artificial intelligence),neural nets,Neural networks,operational classifier,regularization,remote sensing,semisupervised learning,semisupervised learning (SSL),semisupervised neural networks,Stochastic processes,support vector machine (SVM),Support vector machine classification,support vector machines,transductive support vector machines,transductive SVM (TSVM),Unsupervised learning},
  pages = {2271-2282},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/97RQZAW3/5411821.html}
}

@article{tuia_multiclass_2015,
  title = {Multiclass Feature Learning for Hyperspectral Image Classification: {{Sparse}} and Hierarchical Solutions},
  volume = {105},
  issn = {0924-2716},
  shorttitle = {Multiclass Feature Learning for Hyperspectral Image Classification},
  doi = {10.1016/j.isprsjprs.2015.01.006},
  abstract = {In this paper, we tackle the question of discovering an effective set of spatial filters to solve hyperspectral classification problems. Instead of fixing a priori the filters and their parameters using expert knowledge, we let the model find them within random draws in the (possibly infinite) space of possible filters. We define an active set feature learner that includes in the model only features that improve the classifier. To this end, we consider a fast and linear classifier, multiclass logistic classification, and show that with a good representation (the filters discovered), such a simple classifier can reach at least state of the art performances. We apply the proposed active set learner in four hyperspectral image classification problems, including agricultural and urban classification at different resolutions, as well as multimodal data. We also propose a hierarchical setting, which allows to generate more complex banks of features that can better describe the nonlinearities present in the data.},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  author = {Tuia, Devis and Flamary, R{\'e}mi and Courty, Nicolas},
  month = jul,
  year = {2015},
  keywords = {hyperspectral imaging,deep learning,Active set,Feature selection,Multimodal,Hierarchical feature extraction},
  pages = {272-285},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/2BJEKH2X/S0924271615000234.html}
}

@inproceedings{midhun_deep_2014,
  address = {New York, NY, USA},
  series = {ICONIAAC '14},
  title = {Deep {{Model}} for {{Classification}} of {{Hyperspectral Image Using Restricted Boltzmann Machine}}},
  isbn = {978-1-4503-2908-8},
  doi = {10.1145/2660859.2660946},
  abstract = {This paper presents an improved classification of hyperspectral images using deep learning, by extracting meaningful representations at higher levels. Deep learning is a set of algorithm in machine learning that attempt to model high level abstraction of data by using architectures composed of multiple non-linear transformation. It allows artificial systems to discover re-usable features that capture structure in an environment. The ability of undirected graphical models like Restricted Boltzmann Machine, to capture distribution among pixels at the hidden level is utilized here to extract features for each band in the hyperspectral image. To enhance the quality of image a band-by-band non-linear diffusion is introduced as a preprocessing step which ensures increased class separability and noise reduction. After preprocessing, a powerful regenerative model Restricted Boltzmann Machine (RBM) is used for the feature extraction. The generated feature vectors is feed as input to different classifiers for the classification. A statistical comparison of accuracies, obtained with RBM under different conditions illustrates the effectiveness of proposed method. Hyperspectral dataset acquired by Airborne Visible/Infrared imaging Spectrometer is used for experimentation.},
  booktitle = {Proceedings of the 2014 {{International Conference}} on {{Interdisciplinary Advances}} in {{Applied Computing}}},
  publisher = {{ACM}},
  author = {Midhun, M. E. and Nair, Sarath R and Prabhakar, V. T. Nidhin and Kumar, S. Sachin},
  year = {2014},
  keywords = {deep learning,image classification,restricted Boltzmann machine,Diffusion,Feature Generation,Hyperspectral imagery},
  pages = {35:1--35:7},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/8F32WNVN/Midhun et al_2014_Deep Model for Classification of Hyperspectral Image Using Restricted Boltzmann.pdf}
}

@article{pan_r-vcanet_2017,
  title = {R-{{VCANet}}: {{A New Deep}}-{{Learning}}-{{Based Hyperspectral Image Classification Method}}},
  volume = {10},
  issn = {1939-1404},
  shorttitle = {R-{{VCANet}}},
  doi = {10.1109/JSTARS.2017.2655516},
  abstract = {Deep-learning-based methods have displayed promising performance for hyperspectral image (HSI) classification, due to their capacity of extracting deep features from HSI. However, these methods usually require a large number of training samples. It is quite difficult for deep-learning model to provide representative feature expression for HSI data when the number of samples are limited. In this paper, a novel simplified deep-learning model, rolling guidance filter (RGF) and vertex component analysis network (R-VCANet), is proposed, which achieves higher accuracy when the number of training samples is not abundant. In R-VCANet, the inherent properties of HSI data, spatial information and spectral characteristics, are utilized to construct the network. And by this means the obtained model could generate more powerful feature expression with less samples. First, spectral and spatial information are combined via the RGF, which could explore the contextual structure features and remove small details from HSI. More importantly, we have designed a new network called vertex component analysis network for deep features extraction from the smoothed HSI. Experiments on three popular datasets indicate that the proposed R-VCANet based method reveals better performance than some state-of-the-art methods, especially when the training samples available are not abundant.},
  number = {5},
  journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  author = {Pan, B. and Shi, Z. and Xu, X.},
  month = may,
  year = {2017},
  keywords = {contextual structure feature,convolution,data mining,deep feature extraction,deep learning,deep-learning-based hyperspectral image classification method,feature extraction,HSI classification,hyperspectral image (HSI) classification,hyperspectral imaging,image classification,image filtering,learning (artificial intelligence),limited samples,principal component analysis,R-VCANet,representative feature expression,RGF,rolling guidance filter,rolling guidance filter (RGF) and vertex component analysis network (R-VCANet),spatial information,Spectral analysis,spectral characteristics,spectral information,Training,vertex component analysis network},
  pages = {1975-1986},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/9V2AAW7N/7855674.html}
}

@article{chen_deep_2016,
  title = {Deep {{Feature Extraction}} and {{Classification}} of {{Hyperspectral Images Based}} on {{Convolutional Neural Networks}}},
  volume = {54},
  issn = {0196-2892},
  doi = {10.1109/TGRS.2016.2584107},
  abstract = {Due to the advantages of deep learning, in this paper, a regularized deep feature extraction (FE) method is presented for hyperspectral image (HSI) classification using a convolutional neural network (CNN). The proposed approach employs several convolutional and pooling layers to extract deep features from HSIs, which are nonlinear, discriminant, and invariant. These features are useful for image classification and target detection. Furthermore, in order to address the common issue of imbalance between high dimensionality and limited availability of training samples for the classification of HSI, a few strategies such as L2 regularization and dropout are investigated to avoid overfitting in class data modeling. More importantly, we propose a 3-D CNN-based FE model with combined regularization to extract effective spectral-spatial features of hyperspectral imagery. Finally, in order to further improve the performance, a virtual sample enhanced method is proposed. The proposed approaches are carried out on three widely used hyperspectral data sets: Indian Pines, University of Pavia, and Kennedy Space Center. The obtained results reveal that the proposed models with sparse constraints provide competitive results to state-of-the-art methods. In addition, the proposed deep FE opens a new window for further research.},
  number = {10},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Chen, Yushi and Jiang, Hanlu and Li, Chunyang and Jia, Xiuping and Ghamisi, Pedram},
  month = oct,
  year = {2016},
  keywords = {class data modeling,CNN-based FE model,convolutional neural network (CNN),convolutional neural networks,data mining,deep learning,feature extraction,feature extraction (FE),geophysical techniques,hyperspectral image (HSI) classification,hyperspectral images,hyperspectral imaging,Indian Pines,Iron,Kennedy Space Center,Machine learning,neural nets,pooling layers,regularized deep feature extraction,state-of-the-art methods,Training,University of Pavia},
  pages = {6232-6251},
  file = {/home/naudeber/Bibliographie//IEEE Transactions on Geoscience and Remote Sensing/2016/Chen et al 2016 - Deep Feature Extraction and Classification of Hyperspectral Images Based on.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/43SS934F/7514991.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/6ZGJ3ZHM/7514991.html}
}

@article{ma_spectral-spatial_2016,
  title = {Spectral-{{Spatial Classification}} of {{Hyperspectral Image Based}} on {{Deep Auto}}-{{Encoder}}},
  volume = {9},
  issn = {1939-1404},
  doi = {10.1109/JSTARS.2016.2517204},
  abstract = {Deep learning, which represents data by a hierarchical network, has proven to be efficient in computer vision. To investigate the effect of deep features in hyperspectral image (HSI) classification, this paper focuses on how to extract and utilize deep features in HSI classification framework. First, in order to extract spectral-spatial information, an improved deep network, spatial updated deep auto-encoder (SDAE), is proposed. SDAE, which is an improved deep auto-encoder (DAE), considers sample similarity by adding a regularization term in the energy function, and updates features by integrating contextual information. Second, in order to deal with the small training set using deep features, a collaborative representation-based classification is applied. Moreover, in order to suppress salt-and-pepper noise and smooth the result, we compute the residual of collaborative representation of all samples as a residual matrix, which can be effectively used in a graph-cut-based spatial regularization. The proposed method inherits the advantages of deep learning and has solutions to add spatial information of HSI in the learning network. Using collaborative representation-based classification with deep features makes the proposed classifier extremely robust under a small training set. Extensive experiments demonstrate that the proposed method provides encouraging results compared with some related techniques.},
  number = {9},
  journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  author = {Ma, X. and Wang, H. and Geng, J.},
  month = sep,
  year = {2016},
  keywords = {Collaboration,computer vision,data mining,Deep auto-encoders (DAE),deep learning,deep network,feature extraction,feature learning,hyperspectral image (HSI),hyperspectral image spectral-spatial classification,hyperspectral imaging,image classification,Kernel,Machine learning,remote sensing,representation-based classification,residual matrix,spatial updated deep autoencoder,supervised classification,Training},
  pages = {4073-4085},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/ZX79BCT2/7405235.html}
}

@article{tao_unsupervised_2015,
  title = {Unsupervised {{Spectral}}-{{Spatial Feature Learning With Stacked Sparse Autoencoder}} for {{Hyperspectral Imagery Classification}}},
  volume = {12},
  issn = {1545-598X},
  doi = {10.1109/LGRS.2015.2482520},
  abstract = {In this letter, different from traditional methods using original spectral features or handcraft spectral-spatial features, we propose to adaptively learn a suitable feature representation from unlabeled data. This is achieved by learning a feature mapping function based on stacked sparse autoencoder. Considering that hyperspectral imagery (HSI) is intrinsically defined in both the spectral and spatial domains, we further establish two variants of feature learning procedures for sparse spectral feature learning and multiscale spatial feature learning. Finally, we embed the learned spectral-spatial feature into a linear support vector machine for classification. Experiments on two hyperspectral images indicate the following: 1) the learned spectral-spatial feature representation is more discriminative for HSI classification compared to previously hand-engineered spectral-spatial features, especially when the training data are limited and 2) the learned features appear not to be specific to a particular image but general in that they are applicable to multiple related images (e.g., images acquired by the same sensor but varying with location or time).},
  number = {12},
  journal = {IEEE Geoscience and Remote Sensing Letters},
  author = {Tao, C. and Pan, H. and Li, Y. and Zou, Z.},
  month = dec,
  year = {2015},
  keywords = {feature extraction,feature mapping function,feature representation,handcraft spectral-spatial features,Hyperspectral imagery (HSI) classification,hyperspectral imagery classification,hyperspectral imaging,image representation,linear support vector machine,multiple related images,multiscale spatial feature learning,spectral–spatial feature learning,spectral???spatial feature learning,stacked sparse autoencoder,stacked sparse autoencoder (SSAE),Standards,support vector machines,Training,training data,unlabeled data,Unsupervised learning,unsupervised spectral-spatial feature learning},
  pages = {2438-2442},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/HX92QVP4/7296592.html}
}

@inproceedings{ceamanos_using_2017,
  title = {Using {{3D}} Information for Atmospheric Correction of Airborne Hyperspectral Images of Urban Areas},
  doi = {10.1109/JURSE.2017.7924563},
  abstract = {In this paper the benefits of using 3D data on surface elevation of urban areas are investigated to compensate airborne hyperspectral images for atmospheric effects. The strong relief that is characteristic of most cities due to buildings and other 3D objects results in radiative effects that are not taken into account by classical atmospheric correction methods considering a flat surface. The algorithm ICARE-HS (Inversion Code for urban Areas Reflectance Extraction using HyperSpectral imagery) overcomes this limitation using 3D data on the surface coming from lidar or stereoscopic imagery. A digital surface model of the urban area is combined with ray tracing techniques to simulate relief-related radiative effects such as shadow casting and multiple reflections between objects. In this paper ICARE-HS is applied to airborne hyperspectral data of the city center of Toulouse, France, which are also processed by a standard 2D correction method for comparison.},
  booktitle = {2017 {{Joint Urban Remote Sensing Event}} ({{JURSE}})},
  author = {Ceamanos, X. and Briottet, X. and Roussel, G. and Gilardy, H. and Adeline, K.},
  month = mar,
  year = {2017},
  keywords = {Atmospheric modeling,hyperspectral imaging,Reflectivity,Surface treatment,Three-dimensional displays,Urban areas},
  pages = {1-4},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/GRZHHNZN/7924563.html}
}

@article{gao_atmospheric_2009,
  title = {Atmospheric Correction Algorithms for Hyperspectral Remote Sensing Data of Land and Ocean},
  volume = {113},
  journal = {Remote Sensing of Environment},
  author = {Gao, Bo-Cai and Montes, Marcos J. and Davis, Curtiss O. and Goetz, Alexander FH},
  year = {2009},
  pages = {S17--S24},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/H27KVCIR/S0034425709000741.html}
}

@article{li_spectralspatial_2017,
  title = {Spectral\textendash{{Spatial Classification}} of {{Hyperspectral Imagery}} with {{3D Convolutional Neural Network}}},
  volume = {9},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  doi = {10.3390/rs9010067},
  abstract = {Recent research has shown that using spectral\textendash{}spatial information can considerably improve the performance of hyperspectral image (HSI) classification. HSI data is typically presented in the format of 3D cubes. Thus, 3D spatial filtering naturally offers a simple and effective method for simultaneously extracting the spectral\textendash{}spatial features within such images. In this paper, a 3D convolutional neural network (3D-CNN) framework is proposed for accurate HSI classification. The proposed method views the HSI cube data altogether without relying on any preprocessing or post-processing, extracting the deep spectral\textendash{}spatial-combined features effectively. In addition, it requires fewer parameters than other deep learning-based methods. Thus, the model is lighter, less likely to over-fit, and easier to train. For comparison and validation, we test the proposed method along with three other deep learning-based HSI classification methods\textemdash{}namely, stacked autoencoder (SAE), deep brief network (DBN), and 2D-CNN-based methods\textemdash{}on three real-world HSI datasets captured by different sensors. Experimental results demonstrate that our 3D-CNN-based method outperforms these state-of-the-art methods and sets a new record.},
  language = {en},
  number = {1},
  journal = {Remote Sensing},
  author = {Li, Ying and Zhang, Haokui and Shen, Qiang},
  month = jan,
  year = {2017},
  keywords = {2D convolutional neural networks,3D convolutional neural networks,3D structure,deep learning,hyperspectral image classification},
  pages = {67},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/JN224U6H/Li et al_2017_Spectral–Spatial Classification of Hyperspectral Imagery with 3D Convolutional.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/BAC89TJ3/htm.html}
}

@misc{noauthor_pytorch_2016,
  title = {{{PyTorch}}: {{Tensors}} and {{Dynamic}} Neural Networks in {{Python}} with Strong {{GPU}} Acceleration},
  year = {2016},
  note = {http://pytorch.org/}
}

@inproceedings{lee_contextual_2016,
  address = {Beijing},
  title = {Contextual Deep {{CNN}} Based Hyperspectral Classification},
  doi = {10.1109/IGARSS.2016.7729859},
  booktitle = {2016 {{IEEE International Geoscience}} and {{Remote Sensing Symposium}} ({{IGARSS}})},
  author = {Lee, Hyungtae and Kwoon, Heesung},
  month = jul,
  year = {2016},
  pages = {3322-3325}
}

@article{beucher_morphological_1993,
  title = {The Morphological Approach to Segmentation: The Watershed Transformation. {{Mathematical}} Morphology in Image Processing.},
  volume = {34},
  shorttitle = {The Morphological Approach to Segmentation},
  journal = {Optical Engineering},
  author = {Beucher, Serge and Meyer, Fernand},
  year = {1993},
  pages = {433-481}
}

@inproceedings{nair_rectified_2010,
  title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning ({{ICML}}-10)},
  author = {Nair, Vinod and Hinton, Geoffrey E.},
  year = {2010},
  pages = {807--814},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/U4T6HPKD/reluICML.pdf}
}

@article{mou_deep_2017,
  title = {Deep {{Recurrent Neural Networks}} for {{Hyperspectral Image Classification}}},
  volume = {55},
  issn = {0196-2892},
  doi = {10.1109/TGRS.2016.2636241},
  abstract = {In recent years, vector-based machine learning algorithms, such as random forests, support vector machines, and 1-D convolutional neural networks, have shown promising results in hyperspectral image classification. Such methodologies, nevertheless, can lead to information loss in representing hyperspectral pixels, which intrinsically have a sequence-based data structure. A recurrent neural network (RNN), an important branch of the deep learning family, is mainly designed to handle sequential data. Can sequence-based RNN be an effective method of hyperspectral image classification? In this paper, we propose a novel RNN model that can effectively analyze hyperspectral pixels as sequential data and then determine information categories via network reasoning. As far as we know, this is the first time that an RNN framework has been proposed for hyperspectral image classification. Specifically, our RNN makes use of a newly proposed activation function, parametric rectified tanh (PRetanh), for hyperspectral sequential data analysis instead of the popular tanh or rectified linear unit. The proposed activation function makes it possible to use fairly high learning rates without the risk of divergence during the training procedure. Moreover, a modified gated recurrent unit, which uses PRetanh for hidden representation, is adopted to construct the recurrent layer in our network to efficiently process hyperspectral data and reduce the total number of parameters. Experimental results on three airborne hyperspectral images suggest competitive performance in the proposed mode. In addition, the proposed network architecture opens a new window for future research, showcasing the huge potential of deep recurrent networks for hyperspectral data analysis.},
  number = {7},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Mou, L. and Ghamisi, P. and Zhu, X. X.},
  month = jul,
  year = {2017},
  keywords = {1-D convolutional neural networks,activation function,airborne hyperspectral images,Convolutional neural network (CNN),data analysis,Data models,deep learning,deep learning family,deep recurrent neural networks,gated recurrent unit (GRU),geophysical techniques,hyperspectral data process,hyperspectral image classification,hyperspectral image classification method,hyperspectral imaging,Hyperspectral imaging,hyperspectral pixels,hyperspectral sequential data analysis,image classification,information categories,information loss,Logic gates,long short-term memory (LSTM),modified gated recurrent unit,network architecture,network reasoning,neural nets,parametric rectified tanh,random forests,rectified linear unit,recurrent neural network (RNN),Recurrent neural networks,sequence-based data structure,sequence-based RNN model,sequential data,support vector machines,Support vector machines,vector-based machine learning algorithms},
  pages = {3639-3655},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/QKB4FSKX/cookiedetectresponse.html}
}

@article{hu_deep_2015,
  title = {Deep {{Convolutional Neural Networks}} for {{Hyperspectral Image Classification}}},
  volume = {2015},
  abstract = {Recently, convolutional neural networks have demonstrated excellent performance on various visual tasks, including the classification of common two-dimensional images. In this paper, deep convolutional neural networks are employed to classify hyperspectral images directly in spectral domain. More specifically, the architecture of the proposed classifier contains five layers with weights which are the input layer, the convolutional layer, the max pooling layer, the full connection layer, and the output layer. These five layers are implemented on each spectral signature to discriminate against others. Experimental results based on several hyperspectral image data sets demonstrate that the proposed method can achieve better classification performance than some traditional methods, such as support vector machines and the conventional deep learning-based methods.},
  language = {en},
  journal = {Journal of Sensors},
  author = {Hu, Wei and Huang, Yangyu and Wei, Li and Zhang, Fan and Li, Hengchao},
  year = {2015},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/QM8LIJX4/258619.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/WAKG9UT7/Hu et al. - 2015 - Deep Convolutional Neural Networks for Hyperspectr.pdf},
  doi = {10.1155/2015/258619}
}

@article{luo_hsi-cnn_2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1802.10478},
  primaryClass = {cs},
  title = {{{HSI}}-{{CNN}}: {{A Novel Convolution Neural Network}} for {{Hyperspectral Image}}},
  shorttitle = {{{HSI}}-{{CNN}}},
  abstract = {With the development of deep learning, the performance of hyperspectral image (HSI) classification has been greatly improved in recent years. The shortage of training samples has become a bottleneck for further improvement of performance. In this paper, we propose a novel convolutional neural network framework for the characteristics of hyperspectral image data, called HSI-CNN. Firstly, the spectral-spatial feature is extracted from a target pixel and its neighbors. Then, a number of one-dimensional feature maps, obtained by convolution operation on spectral-spatial features, are stacked into a two-dimensional matrix. Finally, the two-dimensional matrix considered as an image is fed into standard CNN. This is why we call it HSI-CNN. In addition, we also implements two depth network classification models, called HSI-CNN+XGBoost and HSI-CapsNet, in order to compare the performance of our framework. Experiments show that the performance of hyperspectral image classification is improved efficiently with HSI-CNN framework. We evaluate the model's performance using four popular HSI datasets, which are the Kennedy Space Center (KSC), Indian Pines (IP), Pavia University scene (PU) and Salinas scene (SA). As far as we concerned, HSI-CNN has got the state-of-art accuracy among all methods we have known on these datasets of 99.28\%, 99.09\%, 99.42\%, 98.95\% separately.},
  journal = {arXiv:1802.10478 [cs]},
  author = {Luo, Yanan and Zou, Jie and Yao, Chengfei and Li, Tao and Bai, Gang},
  month = feb,
  year = {2018},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/ZGJDDNLB/Luo et al. - 2018 - HSI-CNN A Novel Convolution Neural Network for Hy.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/U3JG2AFZ/1802.html}
}

@article{cui_scalable_2017,
  title = {Scalable {{Bag}} of {{Subpaths Kernel}} for {{Learning}} on {{Hierarchical Image Representations}} and {{Multi}}-{{Source Remote Sensing Data Classification}}},
  volume = {9},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  doi = {10.3390/rs9030196},
  abstract = {The geographic object-based image analysis (GEOBIA) framework has gained increasing interest for the last decade. One of its key advantages is the hierarchical representation of an image, where object topological features can be extracted and modeled in the form of structured data. We thus propose to use a structured kernel relying on the concept of bag of subpaths to directly cope with such features. The kernel can be approximated using random Fourier features, allowing it to be applied on a large structure size (the number of objects in the structured data) and large volumes of data (the number of pixels or regions for training). With the so-called scalable bag of subpaths kernel (SBoSK), we also introduce a novel multi-source classification approach performing machine learning directly on a hierarchical image representation built from two images at different resolutions under the GEOBIA framework. Experiments run on an urban classification task show that the proposed approach run on a single image improves the classification overall accuracy in comparison with conventional approaches from 2\% to 5\% depending on the training set size and that fusing two images allows a supplementary 4\% accuracy gain. Additional evaluations on public available large-scale datasets illustrate further the potential of SBoSK, with overall accuracy rates improvement ranging from 1\% to 11\% depending on the considered setup.},
  language = {en},
  number = {3},
  journal = {Remote Sensing},
  author = {Cui, Yanwei and Chapel, Laetitia and Lef{\`e}vre, S{\'e}bastien},
  month = feb,
  year = {2017},
  keywords = {GEOBIA,hierarchical representations,kernel approximation,large-scale machine learning,random Fourier features,structured kernel},
  pages = {196},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/KM7BUVGJ/Cui et al. - 2017 - Scalable Bag of Subpaths Kernel for Learning on Hi.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/YMPSRPTJ/Cui et al. - 2017 - Scalable Bag of Subpaths Kernel for Learning on Hi.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/BX5XQIW2/196.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/E3U5W433/196.html}
}

@article{myneni_interpretation_1995,
  title = {The Interpretation of Spectral Vegetation Indexes},
  volume = {33},
  issn = {0196-2892},
  doi = {10.1109/36.377948},
  abstract = {Empirical studies report several plausible correlations between transforms of spectral reflectance, called vegetation indexes, and parameters descriptive of vegetation leaf area, biomass and physiological functioning. However, most indexes can be generalized to show a derivative of surface reflectance with respect to wavelength. This derivative is a function of the optical properties of leaves and soil particles. In the case of optically dense vegetation, the spectral derivative, and thus the indexes, can be rigorously shown to be indicative of the abundance and activity of the absorbers in the leaves. Therefore, the widely used broad-band red/near-infrared vegetation indexes are a measure of chlorophyll abundance and energy absorption},
  number = {2},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Myneni, Ranga B. and Hall, Forrest G. and Sellers, Piers J. and Marshak, Alexander L.},
  month = mar,
  year = {1995},
  keywords = {geophysical techniques,Vegetation,remote sensing,Reflectivity,spectral reflectance,Remote sensing,vegetation,forestry,NASA,500 to 1500 nm,Absorption,biomass,Biomedical optical imaging,chlorophyll,correlations,forest,geophysical measurement technique,infrared imaging,IR method,land surface,light reflection visible,near-infrared,optical imaging,Optical sensors,physiological functioning,Postal services,Soil measurements,spectra,spectral vegetation index,vegetation leaf area,Wavelength measurement},
  pages = {481-486},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/35ED8PBL/cookiedetectresponse.html}
}

@inproceedings{sakamoto_automatic_2004,
  title = {Automatic Detection of Damaged Area of {{Iran}} Earthquake by High-Resolution Satellite Imagery},
  volume = {2},
  doi = {10.1109/IGARSS.2004.1368685},
  abstract = {The huge earthquake of magnitude 6.3 had occurred at Bam city of southeastern Iran on December 26, 2003. The author applied nonlinear mapping method for detection of collapsed building area due to Iran earthquake with high-resolution QuickBird satellite images. As a result, ROC evaluation based on the result of photo interpretation by operator showed that the detection ratio of the proposed method is 75-90\% of changed area with 20\% of false alarm.},
  booktitle = {{{IGARSS}} 2004. 2004 {{IEEE International Geoscience}} and {{Remote Sensing Symposium}}},
  author = {Sakamoto, M. and Takasago, Y. and Uto, K. and Kakumoto, S. and Kosugi, Y. and Doihara, T.},
  month = sep,
  year = {2004},
  keywords = {terrain mapping,Neural networks,Satellites,remote sensing,Cities and towns,Robustness,image processing,AD 2003 12 26,Asia,automatic damage detection,Bam city,collapsed building area,Costs,earthquake,Earthquake engineering,earthquakes,Image matching,Iterative methods,Lenses,nonlinear mapping method,photo interpretation,ROC evaluation,southeastern Iran},
  pages = {1418-1421 vol.2},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/NSNHFHT6/1368685.html}
}

@article{pedregosa_scikit-learn_2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  volume = {12},
  issn = {ISSN 1533-7928},
  shorttitle = {Scikit-Learn},
  number = {Oct},
  journal = {Journal of Machine Learning Research},
  author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'E}douard},
  year = {2011},
  pages = {2825-2830},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/E7YAAB9W/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/C8YJPV24/pedregosa11a.html}
}

@article{paszke_automatic_2017,
  title = {Automatic Differentiation in {{PyTorch}}},
  abstract = {In this article, we describe an automatic differentiation module of PyTorch \textemdash{} a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua...},
  author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  month = oct,
  year = {2017},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/V23AHCLW/Paszke et al. - 2017 - Automatic differentiation in PyTorch.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/PUM22BCB/forum.html}
}

@misc{arino_global_2012,
  title = {Global {{Land Cover Map}} for 2009 ({{GlobCover}} 2009)},
  doi = {https://doi.org/10.1594/PANGAEA.787668},
  abstract = {Arino, Olivier; Ramos Perez, Jose Julio; Kalogirou, Vasileios; Bontemps, Sophie; Defourny, Pierre; Van Bogaert, Eric (2012): Global Land Cover Map for 2009 (GlobCover 2009). \textcopyright{} European Space Agency (ESA) \& Universit{\'e} catholique de Louvain (UCL), PANGAEA, https://doi.org/10.1594/PANGAEA.787668},
  language = {en},
  journal = {\textcopyright{} European Space Agency (ESA) \& Universit{\'e} catholique de Louvain (UCL)},
  author = {Arino, Olivier and Ramos Perez, Jose Julio and Kalogirou, Vasileios and Bontemps, Sophie and Defourny, Pierre and Van Bogaert, Eric},
  month = aug,
  year = {2012},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/LHAMX3CX/PANGAEA.html}
}

@inproceedings{bevilacqua_unsupervised_2017,
  address = {P{\'e}kin, China},
  title = {Unsupervised Hyperspectral Band Selection via Multi-Feature Information-Maximization Clustering},
  doi = {10.1109/ICIP.2017.8296339},
  abstract = {This paper presents a new approach for unsupervised band selection in the context of hyperspectral imaging. The hyperspectral band selection (HBS) task is considered as a clustering problem: bands are clustered in the image space; one representative image is then kept for each cluster, to be part of the set of selected bands. The proposed clustering method falls into the family of information-maximization clustering, where mutual information between data features and cluster assignments is maximized. Inspired by a clustering method of this family, we adapt it to the HBS problem and extend it to the case of multiple image features. A pixel selection step is also integrated to reduce the spatial support of the feature vectors, thus mitigating the curse of dimensionality. Experiments with different standard data sets show that the bands selected with our algorithm lead to higher classification performance, in comparison with other state-of-the-art HBS methods.},
  booktitle = {2017 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  publisher = {{IEEE}},
  author = {Bevilacqua, Marco and Berthoumieu, Yannick},
  month = sep,
  year = {2017},
  keywords = {band selection,classification,clustering,dimen- sionality reduction,Hyperspectral imaging},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/CEAJCE2E/Bevilacqua et Berthoumieu - 2017 - Unsupervised hyperspectral band selection via mult.pdf}
}

@inproceedings{he_multi-scale_2017,
  title = {Multi-Scale {{3D}} Deep Convolutional Neural Network for Hyperspectral Image Classification},
  doi = {10.1109/ICIP.2017.8297014},
  abstract = {Research in deep neural network (DNN) and deep learning has great progress for 1D (speech), 2D (image) and 3D (3D-object) recognition/classification problems. As HSI that with 2D spatial and 1D spectral information is quite different from 3D object image, the existing DNN cannot be directly extended to hyperspectral image (HSI) classification. A Multiscale 3D deep convolutional neural network (M3D-DCNN) is proposed for HSI classification, which could jointly learn both 2D Multi-scale spatial feature and 1D spectral feature from HSI data in an end-to-end approach, promising to achieve better results with large-scale dataset. Although without any hand-craft features or pre/post-processing like PCA, sparse coding etc, we achieve the state-of-the-art results on the standard datasets, which shows the technical validity and advancement of our method.},
  booktitle = {2017 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author = {He, M. and Li, B. and Chen, H.},
  month = sep,
  year = {2017},
  keywords = {1D spectral feature,1D spectral information,2D Multiscale spatial feature,3D convolution,3D object image,3D-object classification,3D-object recognition,convolution,Convolution,deep learning,deep neural network,DNN,end-to-end,feature extraction,Feature extraction,feedforward neural nets,geophysical image processing,HSI classification,HSI data,hyperspectral image classification,Hyperspectral image classification,hyperspectral imaging,Hyperspectral imaging,image classification,Kernel,learning (artificial intelligence),M3D-DCNN,multi-scale,Multiscale 3D deep convolutional neural network,stereo image processing,Three-dimensional displays,Training,Two dimensional displays},
  pages = {3904-3908},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/4VTF76IK/He et al. - 2017 - Multi-scale 3D deep convolutional neural network f.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/JBJUN4TU/8297014.html}
}

@article{liu_semi-supervised_2017,
  title = {A Semi-Supervised Convolutional Neural Network for Hyperspectral Image Classification},
  volume = {8},
  issn = {2150-704X},
  doi = {10.1080/2150704X.2017.1331053},
  abstract = {Convolutional neural network (CNN) for hyperspectral image classification can provide excellent performance when the number of labeled samples for training is sufficiently large. Unfortunately, a small number of labeled samples are available for training in hyperspectral images. In this letter, a novel semi-supervised convolutional neural network is proposed for the classification of hyperspectral image. The proposed network can automatically learn features from complex hyperspectral image data structures. Furthermore, skip connection parameters are added between the encoder layer and decoder layer in order to make the network suitable for semi-supervised learning. Semi-supervised method is adopted to solve the problem of limited labeled samples. Finally, the network is trained to simultaneously minimize the sum of supervised and unsupervised cost functions. The proposed network is conducted on a widely used hyperspectral image data. The experimental results demonstrate that the proposed approach provides competitive results to state-of-the-art methods.},
  number = {9},
  journal = {Remote Sensing Letters},
  author = {Liu, Bing and Yu, Xuchu and Zhang, Pengqiang and Tan, Xiong and Yu, Anzhu and Xue, Zhixiang},
  month = sep,
  year = {2017},
  pages = {839-848},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/EL2V4I7W/2150704X.2017.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/H2L8ZAZZ/2150704X.2017.html}
}

@misc{python_software_foundation_python_nodate,
  title = {Python {{Language Reference}}},
  author = {Python Software Foundation},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/XLV882K4/www.python.org.html},
  note = {https://www.python.org/}
}

@article{yang_convolutional_2017,
  title = {A {{Convolutional Neural Network}}-{{Based 3D Semantic Labeling Method}} for {{ALS Point Clouds}}},
  volume = {9},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  doi = {10.3390/rs9090936},
  abstract = {3D semantic labeling is a fundamental task in airborne laser scanning (ALS) point clouds processing. The complexity of observed scenes and the irregularity of point distributions make this task quite challenging. Existing methods rely on a large number of features for the LiDAR points and the interaction of neighboring points, but cannot exploit the potential of them. In this paper, a convolutional neural network (CNN) based method that extracts the high-level representation of features is used. A point-based feature image-generation method is proposed that transforms the 3D neighborhood features of a point into a 2D image. First, for each point in the ALS data, the local geometric features, global geometric features and full-waveform features of its neighboring points within a window are extracted and transformed into an image. Then, the feature images are treated as the input of a CNN model for a 3D semantic labeling task. Finally, to allow performance comparisons with existing approaches, we evaluate our framework on the publicly available datasets provided by the International Society for Photogrammetry and Remote Sensing Working Groups II/4 (ISPRS WG II/4) benchmark tests on 3D labeling. The experiment results achieve 82.3\% overall accuracy, which is the best among all considered methods.},
  language = {en},
  number = {9},
  journal = {Remote Sensing},
  author = {Yang, Zhishuang and Jiang, Wanshou and Xu, Bo and Zhu, Quansheng and Jiang, San and Huang, Wei},
  month = sep,
  year = {2017},
  keywords = {ALS point clouds,deep convolutional neural network,feature image,semantic 3D labeling},
  pages = {936},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/8PJXV639/Yang et al. - 2017 - A Convolutional Neural Network-Based 3D Semantic L.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/5Z4Z9T66/936.html}
}

@article{yan_urban_2015,
  title = {Urban Land Cover Classification Using Airborne {{LiDAR}} Data: {{A}} Review},
  volume = {158},
  issn = {0034-4257},
  shorttitle = {Urban Land Cover Classification Using Airborne {{LiDAR}} Data},
  doi = {10.1016/j.rse.2014.11.001},
  abstract = {Distribution of land cover has a profound impact on the climate and environment; mapping the land cover patterns from global, regional to local scales are important for scientists and authorities to yield better monitoring of the changing world. Satellite remote sensing has been demonstrated as an efficient tool to monitor the land cover patterns for a large spatial extent. Nevertheless, the demand on land cover maps at a finer scale (especially in urban areas) has been raised with evidence by numerous biophysical and socio-economic studies. This paper reviews the small-footprint LiDAR sensor \textemdash{} one of the latest high resolution airborne remote sensing technologies, and its application on urban land cover classification. While most of the early researches focus on the analysis of geometric components of 3D LiDAR data point clouds, there has been an increasing interest in investigating the use of intensity data, waveform data and multi-sensor data to facilitate land cover classification and object recognition in urban environment. In this paper, the advancement of airborne LiDAR technology, including data configuration, feature spaces, classification techniques, and radiometric calibration/correction is reviewed and discussed. The review mainly focuses on the LiDAR studies conducted during the last decade with an emphasis on identification of the approach, analysis of pros and cons, investigating the overall accuracy of the technology, and how the classification results can serve as an input for different urban environmental analyses. Finally, several promising directions for future LiDAR research are highlighted, in hope that it will pave the way for the applications of urban environmental modeling and assessment at a finer scale and a greater extent.},
  journal = {Remote Sensing of Environment},
  author = {Yan, Wai Yeung and Shaker, Ahmed and {El-Ashmawy}, Nagwa},
  month = mar,
  year = {2015},
  keywords = {Airborne LiDAR,Full-waveform,Land cover classification,Land cover mapping,Laser scanning,LiDAR intensity,Radiometric calibration,Radiometric correction,Urban analysis,Urban environment},
  pages = {295-310},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/WSSW7JIT/Yan et al. - 2015 - Urban land cover classification using airborne LiD.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/7CMAFDIA/S0034425714004374.html}
}

@article{chen_state---art_2017,
  title = {State-of-the-{{Art}}: {{DTM Generation Using Airborne LIDAR Data}}},
  volume = {17},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  shorttitle = {State-of-the-{{Art}}},
  doi = {10.3390/s17010150},
  abstract = {Digital terrain model (DTM) generation is the fundamental application of airborne Lidar data. In past decades, a large body of studies has been conducted to present and experiment a variety of DTM generation methods. Although great progress has been made, DTM generation, especially DTM generation in specific terrain situations, remains challenging. This research introduces the general principles of DTM generation and reviews diverse mainstream DTM generation methods. In accordance with the filtering strategy, these methods are classified into six categories: surface-based adjustment; morphology-based filtering, triangulated irregular network (TIN)-based refinement, segmentation and classification, statistical analysis and multi-scale comparison. Typical methods for each category are briefly introduced and the merits and limitations of each category are discussed accordingly. Despite different categories of filtering strategies, these DTM generation methods present similar difficulties when implemented in sharply changing terrain, areas with dense non-ground features and complicated landscapes. This paper suggests that the fusion of multi-sources and integration of different methods can be effective ways for improving the performance of DTM generation.},
  language = {en},
  number = {1},
  journal = {Sensors},
  author = {Chen, Ziyue and Gao, Bingbo and Devereux, Bernard},
  month = jan,
  year = {2017},
  keywords = {DTM generation,morphology-based,multi-scale comparison,segmentation and classification,statistical analysis,surface-based,TIN-based},
  pages = {150},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/I6KJ6SFX/Chen et al. - 2017 - State-of-the-Art DTM Generation Using Airborne LI.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/68JP3FKM/150.html}
}

@article{toutin_comparison_2004,
  title = {Comparison of Stereo-Extracted {{DTM}} from Different High-Resolution Sensors: {{SPOT}}-5, {{EROS}}-a, {{IKONOS}}-{{II}}, and {{QuickBird}}},
  volume = {42},
  issn = {0196-2892},
  shorttitle = {Comparison of Stereo-Extracted {{DTM}} from Different High-Resolution Sensors},
  doi = {10.1109/TGRS.2004.834641},
  abstract = {Digital elevation models (DEMs) extracted from high-resolution stereo-images (SPOT-5, EROS-A, IKONOS-II, and QuickBird) using a three-dimensional multisensor physical model developed at the Canada Centre for Remote Sensing, Natural Resources Canada were evaluated. In a first step, the photogrammetric bundle adjustment was setup for the stereo-images with few accurate ground control points. In a second step, DEMs were generated using an area-based multiscale image matching method and then compared to 0.2-m accurate light detection and ranging (LIDAR) elevation data. Elevation linear errors with 68\% confidence level (LE68) of 6.5, 20, 6.4, and 6.7 m were achieved for SPOT, EROS, IKONOS, and QuickBird, respectively. The poor results for EROS are mainly due to its asynchronous low orbit, which generated large geometric and radiometric differences. However, when such differences were not large, LE68 of 10 m (four pixels) was achieved. Since the SPOT, IKONOS, and QuickBird DEMs were in fact digital surface models, where the height of land covers was included, elevation accuracy was performed only on bare surfaces (soils and lakes), where there was no difference between the stereo-extracted elevations and the LIDAR data. LE68 of 2.2, 1.5, and 1.2 m were then obtained for SPOT, IKONOS, and QuickBird, respectively. When compared to sensor resolution, multidate across-track SPOT with a smaller base-to-height (B/H) ratio of 0.77 achieved three to four times better results than same-date in-track IKONOS and QuickBird with B/H of around 1: 0.5 pixels versus 1.5 or 2 pixels.},
  number = {10},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Toutin, T.},
  month = oct,
  year = {2004},
  keywords = {3D multisensor physical model,area-based multiscale image matching,asynchronous low orbit,base-to-height ratio,Canada Centre for Remote Sensing,Data mining,DEM,Digital elevation model,digital elevation models,digital surface models,elevation linear errors,EROS-A,feature extraction,geometric differences,geometric evaluation,geophysical signal processing,ground control points,high resolution,high-resolution sensors,high-resolution stereo-images,IKONOS-II,image matching,Image matching,image resolution,image sensors,lakes,land cover height,Land surface,Laser radar,LIDAR elevation data,light detection and ranging,multidate across-track SPOT,Natural Resources Canada,photogrammetric bundle adjustment,photogrammetry,QuickBird,radiometric differences,Radiometry,Remote sensing,Satellite broadcasting,sensor resolution,soils,Solid modeling,SPOT-5,stereo image processing,stereo-extracted DTM,stereoscopy,Surface soil,Surface topography,terrain mapping,topography (Earth)},
  pages = {2121-2129},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/MQCD8J4A/Toutin - 2004 - Comparison of stereo-extracted DTM from different .pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/4GJRZFPU/1344164.html}
}

@inproceedings{ben_hamida_deep_2017,
  title = {Deep Learning for Semantic Segmentation of Remote Sensing Images with Rich Spectral Content},
  doi = {10.1109/IGARSS.2017.8127520},
  abstract = {With the rapid development of Remote Sensing acquisition techniques, there is a need to scale and improve processing tools to cope with the observed increase of both data volume and richness. Among popular techniques in remote sensing, Deep Learning gains increasing interest but depends on the quality of the training data. Therefore, this paper presents recent Deep Learning approaches for fine or coarse land cover semantic segmentation estimation. Various 2D architectures are tested and a new 3D model is introduced in order to jointly process the spatial and spectral dimensions of the data. Such a set of networks enables the comparison of the different spectral fusion schemes. Besides, we also assess the use of a ``noisy ground truth'' (i.e. outdated and low spatial resolution labels) for training and testing the networks.},
  booktitle = {2017 {{IEEE International Geoscience}} and {{Remote Sensing Symposium}} ({{IGARSS}})},
  author = {Ben Hamida, Amina and Benoit, Alexandre and Lambert, Patrick and Klein, Louis and Ben Amar, Chokri and Audebert, Nicolas and Lef{\`e}vre, S{\'e}bastien},
  month = jul,
  year = {2017},
  keywords = {2D architectures,3D model,coarse land cover semantic segmentation estimation,Convolution,data volume,Decoding,Deep Learning,deep learning approach,Estimation,fine land cover semantic segmentation estimation,geophysical image processing,image fusion,image resolution,Image resolution,image segmentation,land cover,learning (artificial intelligence),Multispectral,Neurons,Noisy Training,remote sensing,Remote Sensing,remote sensing acquisition techniques,remote sensing image semantic segmentation,Semantic Segmentation,Semantics,spatial dimensions,spectral dimensions,spectral fusion schemes,Three-dimensional displays,training data},
  pages = {2569-2572},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/NYGQKR69/8127520.html}
}


