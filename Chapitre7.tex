%!TEX root = Manuscrit.tex
\chapter{Conclusion et perspectives}
\label{chap:conclusion}
\citationChap{It is good to have an end to journey toward; but it is the journey that matters, in the end.}{Ursula Le Guin (The Left Hand of Darkness, 1969)}
\minitoc

L'abondance nouvelle de données de télédétection est un véritable trésor pour la communauté scientifique. Grâce aux efforts décuplés investis dans les programmes d'observation de la Terre, nous disposons à présent d'images haute résolution sur l'ensemble du globe à des taux de revisite inégalés par le passé. En France, l'ensemble du territoire est imagé en aérien à \SI{20}{\centi\meter/\px} tous les 3 ans par l'\gls{IGN}, tandis que le \gls{CNES} produit une observation à \SI{1,5}{\meter/\px} de l'ensemble du pays chaque année grâce à \gls{SPOT}. La constellation \gls{Sentinel}-2 du programme européen Copernicus complète ce tableau par des acquisitions hebdomadaires à \SI{10}{\meter/\px} sur la Terre entière. À ces images viennent s'ajouter les données commerciales et de défense (WorldView, Pléïades), mais aussi les acquisitions \glslink{SAR}{radar}, \gls{Lidar} et \glslink{hyperspectral}{hyperspectrales}.

Les ressources humaines sont toutefois largement insuffisantes pour transformer cette masse de données brutes en information concrète. La photointerprétation manuelle est lente et coûteuse. Son automatisation représente un enjeu majeur pour les défis scientifiques d'aujourd'hui et de demain en écologie, en urbanisme, en météorologie ou encore en agriculture. Notre objectif dans cette thèse était de proposer des méthodes d'apprentissage statistique adaptées au problème de cartographie automatique. Nous avons plus spécifiquement choisi d'étudier cette problématique sous l'angle de l'interprétation d'images à l'aide de réseaux de neurones artificiels. En construisant des modèles adaptés, nous nous sommes petit à petit intéressés à la sémantisation d'images aériennes haute résolution, d'images satellitaires multispectrales et images hyperspectrales. Ce faisant, nous avons en outre introduit des architectures multi-modales pour la fusion de données afin d'exploiter les modèles numériques de terrain et les données géographiques ouvertes pour produire des cartes plus précises.

Dans un premier temps, nous avons montré que les méthodes de l'état de l'art utilisant la classification par région pouvaient être avantageusement remplacées par des approches basées sur les réseaux de neurones entièrement convolutifs. En particulier, nous avons mis en évidence le rôle limitant des pré-segmentations non-supervisées pour l'apprentissage statistique et nous avons adapté les réseaux de segmentation sémantique aux images aériennes de télédétection \gls{IRRV} et \gls{RVB}. Nous avons par la suite étendu cette approche aux données satellitaires multispectrales \gls{Sentinel}-2 en montrant expérimentalement la pertinence d'inclure les bandes hors du domaine visible afin de détecter plus de classes. Nous avons également étudié les approches d'apprentissage profond pour la classification de données hyperspectrales, en mettant notamment en avant l'efficacité des approches convolutives 3D sur les hypercubes.

Dans un second temps, nous avons cherché à introduire de l'information auxiliaire dans les modèles orientés image afin de prendre en compte l'ensemble des données disponibles sur les scènes d'intérêt. En particulier, nous avons introduit deux architectures multi-modales de réseaux convolutifs pour la segmentation sémantique permettant de fusionner des données issues de sources hétérogènes. En combinant d'une part images optiques et modèles numériques de terrain et, d'autre part, images optiques et données \glsdesc{OSM}, nous avons pu diminuer le nombre d'erreurs commises par les réseaux profonds mis en \oe{}uvre pour la cartographie sémantique.

Par la suite, nous nous sommes intéressés au comportement des modèles statistiques sur des jeux de données à petite et grande échelles. Dans le cas de l'imagerie hyperspectrale, nous avions en effet constaté que peu de données annotées étaient disponibles pour l'apprentissage de réseaux profonds. Nous avons donc conçu des modèles génératifs utilisant le principe des \gls{GAN} pour la synthèse de spectres artificiels, avec succès. En outre, nous avons validé nos modèles de cartographie sémantique sur des jeux de données à grande échelle présentant des profils variés, notamment en constituant notre propre jeu de données haute résolution couvrant de nombreuses agglomérations du territoire français. Nous avons notamment montré que les réseaux que nous avons considéré étaient en mesure de passer à l'échelle et généralisaient à des scènes très diversifiées.

Enfin, nous avons étudié les techniques permettant de structurer les cartes sémantiques produites par les réseaux, en particulier dans le cadre de l'analyse d'image orientée objet. Nous avons conçu une méthode dite de segmentation avant détection permettant de réaliser une localisation et une reconnaissance fine des types de véhicules présents dans des images aériennes. Notre approche se fondant sur la segmentation permet notamment d'obtenir les formes des véhicules en plus de leur localisation et génère moins de fausses alarmes que les méthodes de l'état de l'art en télédétection. En outre, nous avons proposé une formulation alternative du problème général de segmentation sémantique sous forme de régression de cartes de distance, afin de structurer implicitement les cartes produites par les réseaux profonds. Cette approche nous a permis d'améliorer la qualité visuelle et statistiques des cartes en contraignant le modèle à apprendre les relations spatiales entre objets de la scène.

Dans l'ensemble, nos expériences ont permis de montrer que les réseaux profonds sont un formidable outil pour l'interprétation automatique d'images de télédétection. Les performances de ces modèles sont désormais proches de ce qui est raisonnablement attendu par les experts thématiciens. La production automatique de cartes sémantique à partir d'images optiques, qu'elles soient couleur, multispectrales ou hyperspectrales, semble désormais atteignable à une échelle industrielle d'ici quelques années, y compris dans un cadre multi-modal. Toutefois, le travail ne peut s'arrêter ici. En effet, nous avons délimité le domaine d'étude de cette thèse aux images optiques sans considération  de l'aspect temporel des acquisitions. Or, l'analyse géographique ne peut s'interpréter que dans le temps. C'est en effet l'évolution des cartes sémantiques qui est intéressante, par exemple pour la surveillance des typhons ou le suivi de la déforestation. S'il est possible de simplement générer de nouvelles cartes à chaque acquisition, des approches incrémentales prenant l'aspect temporel en compte seraient plus économes et plus expressives. Ainsi, il apparaît nécessaire de s'intéresser au traitement des séries temporelles d'images de télédétection, afin de détecter des changements et de faire apparaître des tendances. Enfin, si l'apprentissage profond permet d'obtenir d'excellents résultats en pratique, l'interprétabilité des résultats pour les utilisateurs finaux demeure un enjeu majeur. Les représentations apprises par ces modèles statistiques sont difficilement exploitables par l'humain et ne véhiculent qu'une information limitée. L'apprentissage actif, permettant d'inclure la connaissance experte de l'humain, et l'interprétabilité des modèles, afin de permettre aux spécialistes de comprendre les prédictions des modèles, sont deux axes prometteurs de recherche permettant une meilleure interaction entre les utilisateurs et la machine.

\newpage
