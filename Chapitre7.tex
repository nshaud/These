%!TEX root = Manuscrit.tex
\chapter{Conclusion et perspectives}
\label{chap:conclusion}
\citationChap{It is good to have an end to journey toward; but it is the journey that matters, in the end.}{Ursula Le Guin (The Left Hand of Darkness, 1969)}
\minitoc

L'abondance nouvelle de données de télédétection est un véritable trésor pour la communauté scientifique. Grâce aux efforts décuplés investis dans les programmes d'observation de la Terre, nous disposons à présent d'images haute résolution sur l'ensemble du globe à des taux de revisite inégalés par le passé. En France, l'ensemble du territoire est imagé en aérien à \SI{20}{\centi\meter/\px} tous les 3 ans par l'\gls{IGN}, tandis que le \gls{CNES} produit une observation à \SI{1,5}{\meter/\px} de l'ensemble du pays chaque année grâce à \gls{SPOT}. La constellation \gls{Sentinel}-2 du programme européen Copernicus complète ce tableau par des acquisitions hebdomadaires à \SI{10}{\meter/\px} sur la Terre entière. À ces images viennent s'ajouter les données commerciales et de défense (WorldView, Pléiades), mais aussi les acquisitions \glslink{SAR}{radar}, \gls{Lidar} et \glslink{hyperspectral}{hyperspectrales}.

Les ressources humaines sont toutefois largement insuffisantes pour transformer cette masse de données brutes en information concrète. La photointerprétation manuelle est lente et coûteuse. Son automatisation représente un enjeu majeur pour les défis scientifiques d'aujourd'hui et de demain en écologie, en urbanisme, en météorologie ou encore en agriculture. Notre objectif dans cette thèse était de proposer des méthodes d'apprentissage statistique adaptées au problème de cartographie automatique. En nous appuyant sur les réseaux de neurones artificiels profonds, nous avons construit des modèles pour la sémantisation d'images aériennes et satellitaires à très haute et basse résolution pour une large gamme de capteurs optiques. Afin de tirer parti des données ancillaires comme les modèles numériques de terrain et les données géographiques ouvertes, nous avons en outre introduit des architectures multimodales de fusion de capteurs capables d'exploiter de l'information hétérogène riche. Enfin, nous avons montré les limites des approches sur des jeux de données limités ou massifs et proposé des alternatives, notamment par le biais de la génération de données synthétiques et l'introduction de \emph{MiniFrance}, un nouveau jeu de données annoté à l'échelle de la France.

Ainsi, les travaux présentés dans ce manuscrit ont permis d'établir la place des réseaux profonds comme outil de choix pour l'interprétation automatique d'images de télédétection. Les performances de ces modèles sont désormais proches de ce qui est raisonnablement attendu par les experts thématiciens. En effet, la production automatique de cartes sémantiques à partir d'images optiques, qu'elles soient en couleur, multispectrales ou hyperspectrales, semble désormais réalisable à une échelle industrielle d'ici quelques années, y compris dans un cadre multimodal. Alors que l'apprentissage profond pour la télédétection était encore balbutiant il y a quelques années, il est désormais établi qu'il s'agit d'une approche incontournable. Cette thèse contribue à confirmer cette place mais surtout à étendre son champ d'application aux capteurs optiques inhabituels pour la communauté de la vision par ordinateur. Nous avons introduit des principes conducteurs pouvant servir de guide de bonnes pratiques pour l'application de réseaux convolutifs au vaste domaine de l'interprétation d'images d'observation de la Terre en étudiant les apports du préentraînement, des modules multiéchelles, de la fusion de données et de la régularisation des segmentations. Ces méthodologies encore peu explorées au début des années 2010 sont maintenant établies sur des fondements expérimentaux solides.

Dans un premier temps, nous avons montré que les méthodes de l'état de l'art utilisant la classification par région pouvaient être avantageusement remplacées par des approches basées sur les réseaux de neurones entièrement convolutifs. En particulier, nous avons mis en évidence le rôle limitant des présegmentations non-supervisées pour l'apprentissage statistique et nous avons adapté les réseaux de segmentation sémantique aux images aériennes de télédétection \gls{IRRV} et \gls{RVB}. Nous avons par la suite étendu cette approche aux données satellitaires multispectrales \gls{Sentinel}-2 en montrant expérimentalement la pertinence d'inclure les bandes hors du domaine visible afin de détecter plus de classes. Nous avons également étudié les approches d'apprentissage profond pour la classification de données hyperspectrales, en mettant notamment en avant l'efficacité des approches convolutives 3D sur les hypercubes. Ces contributions ont permis de produire des cartes à des niveaux de précision remplissant les besoins opérationnels pour les utilisateurs et consommateurs de données géographiques.

Dans un second temps, nous avons cherché à introduire de l'information auxiliaire dans les modèles orientés image afin de prendre en compte l'ensemble des données disponibles sur les scènes d'intérêt. En particulier, nous avons introduit deux architectures multimodales de réseaux convolutifs pour la segmentation sémantique permettant de fusionner des données issues de sources hétérogènes. En combinant d'une part images optiques et modèles numériques de terrain et, d'autre part, images optiques et données \glsdesc{OSM}, nous avons pu diminuer le nombre d'erreurs commises par les réseaux profonds mis en \oe{}uvre pour la cartographie sémantique, notamment par le biais de la correction résiduelle. La prise en compte des données \gls{OSM}, entièrement nouvelle, encourage en outre à étudier les possibilités de mise à jour automatique de ce type de base de données par des processus de \emph{bootstrapping}.

Par la suite, nous nous sommes intéressés au comportement des modèles statistiques sur des jeux de données à petite et grande échelles. Dans le cas de l'imagerie hyperspectrale, nous avions en effet constaté que peu de données annotées étaient disponibles pour l'apprentissage de réseaux profonds. Nous avons donc conçu des modèles génératifs utilisant le principe des \gls{GAN} pour la synthèse de spectres artificiels, avec succès. En outre, nous avons validé nos modèles de cartographie sémantique sur des jeux de données à grande échelle présentant des profils variés, notamment en constituant notre propre jeu de données haute résolution couvrant de nombreuses agglomérations du territoire français. Nous avons notamment montré que les réseaux que nous avons considéré étaient en mesure de passer à l'échelle et généralisaient à des scènes très diversifiées. L'introduction du jeu de données \emph{MiniFrance} permettra à terme le préentraînement de modèles supervisés à une échelle encore jamais atteinte pour l'interprétation d'images de télédétection.

Enfin, nous avons étudié les techniques permettant de structurer les cartes sémantiques produites par les réseaux, en particulier dans le cadre de l'analyse d'image orientée objet. Nous avons conçu une méthode dite de segmentation avant détection permettant de réaliser une localisation et une reconnaissance fine des types de véhicules présents dans des images aériennes. Notre approche se fondant sur la segmentation permet notamment d'obtenir les formes des véhicules en plus de leur localisation et génère moins de fausses alarmes que les méthodes de l'état de l'art en télédétection. En outre, nous avons proposé une formulation alternative du problème général de segmentation sémantique sous forme de régression de cartes de distance, afin de structurer implicitement les cartes produites par les réseaux profonds. Cette approche nous a permis d'améliorer la qualité visuelle et statistique des cartes en contraignant le modèle à apprendre les relations spatiales entre objets de la scène. En particulier, la spatialisation des prédictions pixelliques permettra à terme de réaliser de façon unifiée une segmentation panoptique des images, aussi bien multimédia que de télédétection, permettant d'identifier conjointement les instances d'objets mais aussi les surfaces non-structurées.
\medskip
Cela ouvre la voie à de nouvelles pistes de recherche peu ou pas abordées jusqu'ici. Si cette thèse s'est concentrée sur la sémantisation des images, il est indispensable de replacer l'analyse géographique dans son contexte temporel. Du point de vue applicatif, c'est en effet l'évolution des cartes qui est intéressante, aussi bien pour la surveillance des typhons que le suivi de la déforestation. Qu'il s'agisse de détecter les changements entre deux acquisitions ou produire un suivi régulier d'une scène, la génération systématique de cartes complètes pour chaque acquisition est coûteuse. À l'inverse, des méthodes de comparaison d'images ou d'études des séries temporelles, notamment par le biais de réseaux récurrents, permettraient de réaliser une cartographie incrémentale prenant en compte l'historique d'une scène, de façon plus économe mais aussi plus expressive.

Également, il est souhaitable de poursuivre les efforts de traitement de données hétérogènes afin de faire évoluer les architectures multimodales vers le traitement conjoint d'images et de données parcimonieuses ou non structurées, comme des nuages de points, des images au sol ou des annotations textuelles. Les premiers efforts existent en ce sens au travers d'architectures de réseaux modulaires pouvant exploiter de multiples sources de données, robustes à la perte d'une ou plusieurs modalités. Un des défauts couramment soulignés des capteurs optiques étant leur sensibilité aux conditions météorologiques, la prise en compte des données SAR serait notamment une avancée importante pour la cartographie automatisée à haute fréquence. La nature complexe des signaux radar, éloignée du processus habituel de capture d'image, nécessite toutefois des approches spécifiques capables de rendre justice à la physique de tels capteurs. En interprétation de scènes, la prise en compte de la géométrie, soit par reconstruction depuis l'image, soit par intégration d'un capteur type Lidar, permet d'envisager la génération de modèles 3D sémantiques. En télédétection, cela encourage ainsi à se pencher sur des approches combinant géométrie et sémantique pour la photogrammétrie et notamment la génération de modèles de surface et l'orthorectification.

Enfin, si l'apprentissage profond permet d'obtenir d'excellents résultats en pratique, l'interprétabilité des résultats pour les utilisateurs finaux demeure un enjeu majeur. Les représentations apprises par ces modèles statistiques sont difficilement exploitables par l'humain et ne véhiculent qu'une information limitée. L'interprétabilité des modèles, afin de permettre aux spécialistes de comprendre les prédictions des modèles, est un prérequis à la collaboration entre les utilisateurs finaux et la machine. Cela nécessite d'une part d'associer les représentations construites par le réseau à des concepts sémantiques manipulables par l'humain, et d'autre part à rendre explicable le processus de décision en rendant transparent les facteurs ayant eu le plus d'influence. En particulier, cela faciliterait l'apprentissage actif, permettant d'inclure la connaissance de l'humain et de bénéficier aussi bien de son expertise thématique que de ses habitudes de travail.

%\newpage
