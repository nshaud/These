
@inproceedings{makantasis_deep_2015,
  title = {Deep Supervised Learning for Hyperspectral Data Classification through Convolutional Neural Networks},
  doi = {10.1109/IGARSS.2015.7326945},
  abstract = {Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition, which can be consider as a classification task. Most of the existing studies and research efforts are following the conventional pattern recognition paradigm, which is based on the construction of complex handcrafted features. However, it is rarely known which features are important for the problem at hand. In contrast to these approaches, we propose a deep learning based classification method that hierarchically constructs high-level features in an automated way. Our method exploits a Convolutional Neural Network to encode pixels' spectral and spatial information and a Multi-Layer Perceptron to conduct the classification task. Experimental results and quantitative validation on widely used datasets showcasing the potential of the developed approach for accurate hyperspectral data classification.},
  booktitle = {Geoscience and {{Remote Sensing Symposium}} ({{IGARSS}}), 2015 {{IEEE International}}},
  author = {Makantasis, K. and Karantzalos, K. and Doulamis, A. and Doulamis, N.},
  month = jul,
  year = {2015},
  keywords = {Accuracy,neural nets,support vector machines,object recognition,geophysical techniques,hyperspectral imaging,hyperspectral data classification,Neural networks,complex handcrafted construction,conventional pattern recognition paradigm,convolutional neural networks,deep learning based classification method,deep supervised learning,narrow spectral bands,spectral observation,Earth observation,Imaging spectroscopy,Machine learning,Training,image classification},
  pages = {4959-4962},
  file = {/home/naudeber/Bibliographie//undefined/2015/Makantasis et al 2015 - Deep supervised learning for hyperspectral data classification through.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/UZABFHNJ/abs_all.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/WXK4X9RP/7326945.html}
}

@inproceedings{slavkovikj_hyperspectral_2015,
  title = {Hyperspectral {{Image Classification}} with {{Convolutional Neural Networks}}},
  isbn = {978-1-4503-3459-4},
  doi = {10.1145/2733373.2806306},
  language = {en},
  publisher = {{ACM Press}},
  author = {Slavkovikj, Viktor and Verstockt, Steven and De Neve, Wesley and Van Hoecke, Sofie and {Van de Walle}, Rik},
  year = {2015},
  keywords = {hyperspectral imaging,convolutional neural networks,classification,deep learning},
  pages = {1159-1162},
  file = {/home/naudeber/Bibliographie//ACM Press/2015/Slavkovikj et al 2015 - Hyperspectral Image Classification with Convolutional Neural Networks.pdf;/home/naudeber/Bibliographie//ACM/2015/Slavkovikj et al 2015 - Hyperspectral Image Classification with Convolutional Neural Networks.pdf}
}

@article{chen_deep_2016,
  title = {Deep {{Feature Extraction}} and {{Classification}} of {{Hyperspectral Images Based}} on {{Convolutional Neural Networks}}},
  volume = {54},
  issn = {0196-2892},
  doi = {10.1109/TGRS.2016.2584107},
  abstract = {Due to the advantages of deep learning, in this paper, a regularized deep feature extraction (FE) method is presented for hyperspectral image (HSI) classification using a convolutional neural network (CNN). The proposed approach employs several convolutional and pooling layers to extract deep features from HSIs, which are nonlinear, discriminant, and invariant. These features are useful for image classification and target detection. Furthermore, in order to address the common issue of imbalance between high dimensionality and limited availability of training samples for the classification of HSI, a few strategies such as L2 regularization and dropout are investigated to avoid overfitting in class data modeling. More importantly, we propose a 3-D CNN-based FE model with combined regularization to extract effective spectral-spatial features of hyperspectral imagery. Finally, in order to further improve the performance, a virtual sample enhanced method is proposed. The proposed approaches are carried out on three widely used hyperspectral data sets: Indian Pines, University of Pavia, and Kennedy Space Center. The obtained results reveal that the proposed models with sparse constraints provide competitive results to state-of-the-art methods. In addition, the proposed deep FE opens a new window for further research.},
  number = {10},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Chen, Y. and Jiang, H. and Li, C. and Jia, X. and Ghamisi, P.},
  month = oct,
  year = {2016},
  keywords = {class data modeling,CNN-based FE model,convolutional neural network (CNN),convolutional neural networks,data mining,deep learning,feature extraction,feature extraction (FE),geophysical techniques,hyperspectral image (HSI) classification,hyperspectral images,hyperspectral imaging,Indian Pines,Iron,Kennedy Space Center,Machine learning,neural nets,pooling layers,regularized deep feature extraction,state-of-the-art methods,Training,University of Pavia},
  pages = {6232-6251},
  file = {/home/naudeber/Bibliographie//IEEE Transactions on Geoscience and Remote Sensing/2016/Chen et al 2016 - Deep Feature Extraction and Classification of Hyperspectral Images Based on.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/43SS934F/7514991.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/6ZGJ3ZHM/7514991.html}
}

@inproceedings{gemp_inverting_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1608.05983},
  title = {Inverting {{Variational Autoencoders}} for {{Improved Generative Accuracy}}},
  abstract = {Recent advances in semi-supervised learning with deep generative models have shown promise in generalizing from small labeled datasets (\$$\backslash$mathbf\{x\},$\backslash$mathbf\{y\}\$) to large unlabeled ones (\$$\backslash$mathbf\{x\}\$). In the case where the codomain has known structure, a large unfeatured dataset (\$$\backslash$mathbf\{y\}\$) is potentially available. We develop a parameter-efficient, deep semi-supervised generative model for the purpose of exploiting this untapped data source. Empirical results show improved performance in disentangling latent variable semantics as well as improved discriminative prediction on Martian spectroscopic and handwritten digit domains.},
  booktitle = {{{NIPS Workshop}} on {{Advances}} in {{Approximate Bayesian Inference}}},
  author = {Gemp, Ian and Durugkar, Ishan and Parente, Mario and Dyar, M. Darby and Mahadevan, Sridhar},
  year = {2017},
  keywords = {Computer Science - Learning,Statistics - Machine Learning}
}

@inproceedings{maas_rectifier_2013,
  title = {Rectifier Nonlinearities Improve Neural Network Acoustic Models},
  abstract = {Deep neural network acoustic models pro-duce substantial gains in large vocabu-lary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recogni-tion task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2 \% absolute reduc-tions in word error rates over their sigmoidal counterparts. We analyze hidden layer repre-sentations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further im-prove deep rectifier networks. 1.},
  booktitle = {{{ICML Workshop}} on {{Deep Learning}} for {{Audio}}, {{Speech}} and {{Language Processing}}},
  author = {Maas, Andrew L. and Hannun, Awni Y. and Ng, Andrew Y.},
  year = {2013},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/66LFT82M/relu_hybrid_icml2013_final.pdf}
}

@inproceedings{goodfellow_generative_2014,
  title = {Generative {{Adversarial Nets}}},
  booktitle = {Proceedings of the {{Neural Information Processing Systems}} ({{NIPS}})},
  author = {Goodfellow, Ian and {Pouget-Abadie}, Jean and Mirza, Mehdi and Xu, Bing and {Warde-Farley}, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  year = {2014},
  pages = {2672--2680}
}

@inproceedings{salimans_improved_2016,
  title = {Improved {{Techniques}} for {{Training GANs}}},
  booktitle = {Proceedings of the {{Neural Information Processing Systems}} ({{NIPS}})},
  author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
  year = {2016},
  pages = {2234--2242}
}

@inproceedings{krizhevsky_imagenet_2012,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  booktitle = {Proceedings of the {{Neural Information Processing Systems}} ({{NIPS}})},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  year = {2012},
  pages = {1097--1105},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/CPT7II8U/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.html}
}

@inproceedings{gulrajani_improved_2017,
  title = {Improved {{Training}} of {{Wasserstein GANs}}},
  booktitle = {Proceedings of the {{Neural Information Processing Systems}} ({{NIPS}})},
  author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
  year = {2017},
  pages = {5769--5779}
}

@inproceedings{arjovsky_wasserstein_2017,
  title = {Wasserstein {{Generative Adversarial Networks}}},
  abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse...},
  language = {en},
  booktitle = {Proceedings of the {{International Conference}} on {{Machine Learning}} ({{ICML}})},
  author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  month = jul,
  year = {2017},
  pages = {214-223}
}

@inproceedings{lee_contextual_2016,
  address = {Beijing},
  title = {Contextual Deep {{CNN}} Based Hyperspectral Classification},
  doi = {10.1109/IGARSS.2016.7729859},
  booktitle = {2016 {{IEEE International Geoscience}} and {{Remote Sensing Symposium}} ({{IGARSS}})},
  author = {Lee, Hyungtae and Kwoon, Heesung},
  month = jul,
  year = {2016},
  pages = {3322-3325}
}

@article{windrim_hyperspectral_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1611.09007},
  primaryClass = {cs},
  title = {Hyperspectral {{CNN Classification}} with {{Limited Training Samples}}},
  abstract = {Hyperspectral imaging sensors are becoming increasingly popular in robotics applications such as agriculture and mining, and allow per-pixel thematic classification of materials in a scene based on their unique spectral signatures. Recently, convolutional neural networks have shown remarkable performance for classification tasks, but require substantial amounts of labelled training data. This data must sufficiently cover the variability expected to be encountered in the environment. For hyperspectral data, one of the main variations encountered outdoors is due to incident illumination, which can change in spectral shape and intensity depending on the scene geometry. For example, regions occluded from the sun have a lower intensity and their incident irradiance skewed towards shorter wavelengths. In this work, a data augmentation strategy based on relighting is used during training of a hyperspectral convolutional neural network. It allows training to occur in the outdoor environment given only a small labelled region, which does not need to sufficiently represent the geometric variability of the entire scene. This is important for applications where obtaining large amounts of training data is labourious, hazardous or difficult, such as labelling pixels within shadows. Radiometric normalisation approaches for pre-processing the hyperspectral data are analysed and it is shown that methods based on the raw pixel data are sufficient to be used as input for the classifier. This removes the need for external hardware such as calibration boards, which can restrict the application of hyperspectral sensors in robotics applications. Experiments to evaluate the classification system are carried out on two datasets captured from a field-based platform.},
  journal = {arXiv:1611.09007 [cs]},
  author = {Windrim, Lloyd and Ramakrishnan, Rishi and Melkumyan, Arman and Murphy, Richard},
  month = nov,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{acquarelli_convolutional_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1711.05512},
  primaryClass = {cs},
  title = {Convolutional {{Neural Networks}} and {{Data Augmentation}} for {{Spectral}}-{{Spatial Classification}} of {{Hyperspectral Images}}},
  abstract = {Spectral-spatial classification of remotely sensed hyperspectral images has been the subject of many studies in recent years. Current methods achieve excellent performance on benchmark hyperspectral image labeling tasks when a sufficient number of labeled pixels is available. However, in the presence of only very few labeled pixels, such classification becomes a challenging problem. In this paper we propose to tackle this problem using convolutional neural networks (CNNs) and data augmentation. Our newly developed method relies on the assumption of spectral-spatial locality: nearby pixels in a hyperspectral image are related, in the sense that their spectra and their labels are likely to be similar. We exploit this assumption to develop 1) a new data augmentation procedure which adds new samples to the train set and 2) a tailored loss function which penalize differences among weights of the network corresponding to nearby wavelengths of the spectra. We train a simple single layer convolutional neural network with this loss function and augmented train set and use it to classify all unlabeled pixels of the given image. To assess the efficacy of our method, we used five publicly available hyperspectral images: Pavia Center, Pavia University, KSC, Indian Pines and Salina. On these images our method significantly outperforms other baselines. Notably, with just 1\% of labeled pixels per class, on these dataset our method achieves an accuracy of 99.5\%, etc. Furthermore we show that our method improves over other baselines also in a supervised setting, when no overlap between train and test pixels is allowed. Overall our investigation demonstrates that spectral-spatial locality can be easily embedded in a simple convolutional neural network through data augmentation and a tailored loss function.},
  journal = {arXiv:1711.05512 [cs]},
  author = {Acquarelli, Jacopo and Marchiori, Elena and Buydens, Lutgarde M. C. and Tran, Thanh and {van Laarhoven}, Twan},
  month = nov,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{dyk_art_2012,
  title = {The {{Art}} of {{Data Augmentation}}},
  doi = {10.1198/10618600152418584},
  abstract = {(2001). The Art of Data Augmentation. Journal of Computational and Graphical Statistics: Vol. 10, No. 1, pp. 1-50.},
  language = {en},
  journal = {Journal of Computational and Graphical Statistics},
  author = {van Dyk, David A. and Meng, Xiao-Li},
  month = jan,
  year = {2012},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/NEXVNECZ/Dyk and Meng - 2012 - The Art of Data Augmentation.html}
}

@article{pedregosa_scikit-learn_2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  volume = {12},
  issn = {ISSN 1533-7928},
  shorttitle = {Scikit-Learn},
  number = {Oct},
  journal = {Journal of Machine Learning Research},
  author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'E}douard},
  year = {2011},
  pages = {2825-2830},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/E7YAAB9W/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/C8YJPV24/pedregosa11a.html}
}


