
@inproceedings{maggiolo_improving_2018,
  title = {Improving Maps from {{CNNs}} Trained with Sparse, Scribbled Ground Truths Using Fully Connected {{CRFs}}},
  booktitle = {2018 {{IEEE International Geoscience}} and {{Remote Sensing Symposium}} ({{IGARSS}})},
  author = {Maggiolo, Luca and Marcos, Diego and Moser, Gabriele and Tuia, Devis},
  month = jul,
  year = {2018},
  keywords = {Machine learning,Segmentation algorithms,Semantics,Shape,Training,deep learning,feature extraction,image classification,image segmentation,remote sensing,superpixels},
  pages = {2103-2106},
  file = {/home/naudeber/Bibliographie//undefined/2016/Audebert et al 2016 - How useful is region-based classification of remote sensing images in a deep.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/4GRPANQ3/7730327.html}
}

@inproceedings{makantasis_deep_2015,
  title = {Deep Supervised Learning for Hyperspectral Data Classification through Convolutional Neural Networks},
  doi = {10.1109/IGARSS.2015.7326945},
  abstract = {Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition, which can be consider as a classification task. Most of the existing studies and research efforts are following the conventional pattern recognition paradigm, which is based on the construction of complex handcrafted features. However, it is rarely known which features are important for the problem at hand. In contrast to these approaches, we propose a deep learning based classification method that hierarchically constructs high-level features in an automated way. Our method exploits a Convolutional Neural Network to encode pixels' spectral and spatial information and a Multi-Layer Perceptron to conduct the classification task. Experimental results and quantitative validation on widely used datasets showcasing the potential of the developed approach for accurate hyperspectral data classification.},
  booktitle = {Geoscience and {{Remote Sensing Symposium}} ({{IGARSS}}), 2015 {{IEEE International}}},
  author = {Makantasis, Konstantinos and Karantzalos, Konstantinos and Doulamis, Anastasios and Doulamis, Nikolaos},
  month = jul,
  year = {2015},
  keywords = {Accuracy,neural nets,support vector machines,object recognition,geophysical techniques,hyperspectral imaging,hyperspectral data classification,Neural networks,complex handcrafted construction,conventional pattern recognition paradigm,convolutional neural networks,deep learning based classification method,deep supervised learning,narrow spectral bands,spectral observation,Earth observation,Imaging spectroscopy,Machine learning,Training,image classification},
  pages = {4959-4962},
  file = {/home/naudeber/Bibliographie//undefined/2015/Makantasis et al 2015 - Deep supervised learning for hyperspectral data classification through.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/UZABFHNJ/abs_all.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/WXK4X9RP/7326945.html}
}

@inproceedings{slavkovikj_hyperspectral_2015,
  title = {Hyperspectral {{Image Classification}} with {{Convolutional Neural Networks}}},
  isbn = {978-1-4503-3459-4},
  doi = {10.1145/2733373.2806306},
  language = {en},
  booktitle = {Proceedings of the 23rd {{ACM}} International Conference on {{Multimedia}}},
  publisher = {{ACM Press}},
  author = {Slavkovikj, Viktor and Verstockt, Steven and De Neve, Wesley and Van Hoecke, Sofie and {Van de Walle}, Rik},
  year = {2015},
  keywords = {classification,convolutional neural networks,deep learning,hyperspectral imaging},
  pages = {1159-1162},
  file = {/home/naudeber/Bibliographie//ACM Press/2015/Slavkovikj et al 2015 - Hyperspectral Image Classification with Convolutional Neural Networks.pdf;/home/naudeber/Bibliographie//ACM/2015/Slavkovikj et al 2015 - Hyperspectral Image Classification with Convolutional Neural Networks.pdf}
}

@article{chen_deep_2016,
  title = {Deep {{Feature Extraction}} and {{Classification}} of {{Hyperspectral Images Based}} on {{Convolutional Neural Networks}}},
  volume = {54},
  issn = {0196-2892},
  doi = {10.1109/TGRS.2016.2584107},
  abstract = {Due to the advantages of deep learning, in this paper, a regularized deep feature extraction (FE) method is presented for hyperspectral image (HSI) classification using a convolutional neural network (CNN). The proposed approach employs several convolutional and pooling layers to extract deep features from HSIs, which are nonlinear, discriminant, and invariant. These features are useful for image classification and target detection. Furthermore, in order to address the common issue of imbalance between high dimensionality and limited availability of training samples for the classification of HSI, a few strategies such as L2 regularization and dropout are investigated to avoid overfitting in class data modeling. More importantly, we propose a 3-D CNN-based FE model with combined regularization to extract effective spectral-spatial features of hyperspectral imagery. Finally, in order to further improve the performance, a virtual sample enhanced method is proposed. The proposed approaches are carried out on three widely used hyperspectral data sets: Indian Pines, University of Pavia, and Kennedy Space Center. The obtained results reveal that the proposed models with sparse constraints provide competitive results to state-of-the-art methods. In addition, the proposed deep FE opens a new window for further research.},
  number = {10},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  author = {Chen, Yushi and Jiang, Hanlu and Li, Chunyang and Jia, Xiuping and Ghamisi, Pedram},
  month = oct,
  year = {2016},
  keywords = {neural nets,geophysical techniques,hyperspectral imaging,convolutional neural networks,data mining,Machine learning,Training,deep learning,feature extraction,Iron,feature extraction (FE),convolutional neural network (CNN),hyperspectral image (HSI) classification,CNN-based FE model,Indian Pines,Kennedy Space Center,University of Pavia,class data modeling,hyperspectral images,pooling layers,regularized deep feature extraction,state-of-the-art methods},
  pages = {6232-6251},
  file = {/home/naudeber/Bibliographie//IEEE Transactions on Geoscience and Remote Sensing/2016/Chen et al 2016 - Deep Feature Extraction and Classification of Hyperspectral Images Based on.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/43SS934F/7514991.html;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/6ZGJ3ZHM/7514991.html}
}

@inproceedings{gemp_inverting_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1608.05983},
  title = {Inverting {{Variational Autoencoders}} for {{Improved Generative Accuracy}}},
  abstract = {Recent advances in semi-supervised learning with deep generative models have shown promise in generalizing from small labeled datasets (\$$\backslash$mathbf\{x\},$\backslash$mathbf\{y\}\$) to large unlabeled ones (\$$\backslash$mathbf\{x\}\$). In the case where the codomain has known structure, a large unfeatured dataset (\$$\backslash$mathbf\{y\}\$) is potentially available. We develop a parameter-efficient, deep semi-supervised generative model for the purpose of exploiting this untapped data source. Empirical results show improved performance in disentangling latent variable semantics as well as improved discriminative prediction on Martian spectroscopic and handwritten digit domains.},
  booktitle = {{{NIPS Workshop}} on {{Advances}} in {{Approximate Bayesian Inference}}},
  author = {Gemp, Ian and Durugkar, Ishan and Parente, Mario and Dyar, M. Darby and Mahadevan, Sridhar},
  year = {2017},
  keywords = {Computer Science - Learning,Statistics - Machine Learning}
}

@inproceedings{maas_rectifier_2013,
  title = {Rectifier Nonlinearities Improve Neural Network Acoustic Models},
  abstract = {Deep neural network acoustic models pro-duce substantial gains in large vocabu-lary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recogni-tion task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2 \% absolute reduc-tions in word error rates over their sigmoidal counterparts. We analyze hidden layer repre-sentations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further im-prove deep rectifier networks. 1.},
  booktitle = {{{ICML Workshop}} on {{Deep Learning}} for {{Audio}}, {{Speech}} and {{Language Processing}}},
  author = {Maas, Andrew L. and Hannun, Awni Y. and Ng, Andrew Y.},
  year = {2013},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/66LFT82M/relu_hybrid_icml2013_final.pdf}
}

@inproceedings{goodfellow_generative_2014,
  title = {Generative {{Adversarial Nets}}},
  booktitle = {Proceedings of the {{Neural Information Processing Systems}} ({{NIPS}})},
  author = {Goodfellow, Ian and {Pouget-Abadie}, Jean and Mirza, Mehdi and Xu, Bing and {Warde-Farley}, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  year = {2014},
  pages = {2672--2680}
}

@inproceedings{salimans_improved_2016,
  title = {Improved {{Techniques}} for {{Training GANs}}},
  booktitle = {Proceedings of the {{Neural Information Processing Systems}} ({{NIPS}})},
  author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  year = {2016},
  pages = {2234--2242}
}

@inproceedings{krizhevsky_imagenet_2012,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  booktitle = {Proceedings of the {{Neural Information Processing Systems}} ({{NIPS}})},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  year = {2012},
  pages = {1097--1105},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/CPT7II8U/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.html}
}

@inproceedings{gulrajani_improved_2017,
  title = {Improved {{Training}} of {{Wasserstein GANs}}},
  booktitle = {Proceedings of the {{Neural Information Processing Systems}} ({{NIPS}})},
  author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C.},
  year = {2017},
  pages = {5769--5779}
}

@inproceedings{arjovsky_wasserstein_2017,
  title = {Wasserstein {{Generative Adversarial Networks}}},
  abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse...},
  language = {en},
  booktitle = {Proceedings of the {{International Conference}} on {{Machine Learning}} ({{ICML}})},
  author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L\'eon},
  month = jul,
  year = {2017},
  pages = {214-223}
}

@inproceedings{lee_contextual_2016,
  address = {Beijing},
  title = {Contextual Deep {{CNN}} Based Hyperspectral Classification},
  doi = {10.1109/IGARSS.2016.7729859},
  booktitle = {2016 {{IEEE International Geoscience}} and {{Remote Sensing Symposium}} ({{IGARSS}})},
  author = {Lee, Hyungtae and Kwoon, Heesung},
  month = jul,
  year = {2016},
  pages = {3322-3325}
}

@article{windrim_hyperspectral_2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1611.09007},
  primaryClass = {cs},
  title = {Hyperspectral {{CNN Classification}} with {{Limited Training Samples}}},
  abstract = {Hyperspectral imaging sensors are becoming increasingly popular in robotics applications such as agriculture and mining, and allow per-pixel thematic classification of materials in a scene based on their unique spectral signatures. Recently, convolutional neural networks have shown remarkable performance for classification tasks, but require substantial amounts of labelled training data. This data must sufficiently cover the variability expected to be encountered in the environment. For hyperspectral data, one of the main variations encountered outdoors is due to incident illumination, which can change in spectral shape and intensity depending on the scene geometry. For example, regions occluded from the sun have a lower intensity and their incident irradiance skewed towards shorter wavelengths. In this work, a data augmentation strategy based on relighting is used during training of a hyperspectral convolutional neural network. It allows training to occur in the outdoor environment given only a small labelled region, which does not need to sufficiently represent the geometric variability of the entire scene. This is important for applications where obtaining large amounts of training data is labourious, hazardous or difficult, such as labelling pixels within shadows. Radiometric normalisation approaches for pre-processing the hyperspectral data are analysed and it is shown that methods based on the raw pixel data are sufficient to be used as input for the classifier. This removes the need for external hardware such as calibration boards, which can restrict the application of hyperspectral sensors in robotics applications. Experiments to evaluate the classification system are carried out on two datasets captured from a field-based platform.},
  journal = {arXiv:1611.09007 [cs]},
  author = {Windrim, Lloyd and Ramakrishnan, Rishi and Melkumyan, Arman and Murphy, Richard},
  month = nov,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{acquarelli_convolutional_2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1711.05512},
  primaryClass = {cs},
  title = {Convolutional {{Neural Networks}} and {{Data Augmentation}} for {{Spectral}}-{{Spatial Classification}} of {{Hyperspectral Images}}},
  abstract = {Spectral-spatial classification of remotely sensed hyperspectral images has been the subject of many studies in recent years. Current methods achieve excellent performance on benchmark hyperspectral image labeling tasks when a sufficient number of labeled pixels is available. However, in the presence of only very few labeled pixels, such classification becomes a challenging problem. In this paper we propose to tackle this problem using convolutional neural networks (CNNs) and data augmentation. Our newly developed method relies on the assumption of spectral-spatial locality: nearby pixels in a hyperspectral image are related, in the sense that their spectra and their labels are likely to be similar. We exploit this assumption to develop 1) a new data augmentation procedure which adds new samples to the train set and 2) a tailored loss function which penalize differences among weights of the network corresponding to nearby wavelengths of the spectra. We train a simple single layer convolutional neural network with this loss function and augmented train set and use it to classify all unlabeled pixels of the given image. To assess the efficacy of our method, we used five publicly available hyperspectral images: Pavia Center, Pavia University, KSC, Indian Pines and Salina. On these images our method significantly outperforms other baselines. Notably, with just 1\% of labeled pixels per class, on these dataset our method achieves an accuracy of 99.5\%, etc. Furthermore we show that our method improves over other baselines also in a supervised setting, when no overlap between train and test pixels is allowed. Overall our investigation demonstrates that spectral-spatial locality can be easily embedded in a simple convolutional neural network through data augmentation and a tailored loss function.},
  journal = {arXiv:1711.05512 [cs]},
  author = {Acquarelli, Jacopo and Marchiori, Elena and Buydens, Lutgarde M. C. and Tran, Thanh and {van Laarhoven}, Twan},
  month = nov,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{dyk_art_2012,
  title = {The {{Art}} of {{Data Augmentation}}},
  doi = {10.1198/10618600152418584},
  abstract = {(2001). The Art of Data Augmentation. Journal of Computational and Graphical Statistics: Vol. 10, No. 1, pp. 1-50.},
  language = {en},
  journal = {Journal of Computational and Graphical Statistics},
  author = {van Dyk, David A. and Meng, Xiao-Li},
  month = jan,
  year = {2012},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/NEXVNECZ/Dyk and Meng - 2012 - The Art of Data Augmentation.html}
}

@misc{tielman_lecture_2012,
  title = {Lecture 6.5---{{RmsProp}}: {{Divide}} the Gradient by a Running Average of Its Recent Magnitude},
  publisher = {{COURSERA: Neural Networks for Machine Learning}},
  author = {Tielman, T. and Hinton, Geoffrey},
  year = {2012}
}

@inproceedings{odena_conditional_2017,
  title = {Conditional {{Image Synthesis}} with {{Auxiliary Classifier GANs}}},
  abstract = {In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that resu...},
  language = {en},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Odena, Augustus and Olah, Christopher and Shlens, Jonathon},
  month = jul,
  year = {2017},
  pages = {2642-2651},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/6H8JX649/Odena et al. - 2017 - Conditional Image Synthesis with Auxiliary Classif.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/6QMTUAF4/odena17a.html}
}

@article{pedregosa_scikit-learn_2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  volume = {12},
  issn = {ISSN 1533-7928},
  shorttitle = {Scikit-Learn},
  number = {Oct},
  journal = {Journal of Machine Learning Research},
  author = {Pedregosa, Fabian and Varoquaux, Ga\"el and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, \'Edouard},
  year = {2011},
  pages = {2825-2830},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/E7YAAB9W/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/C8YJPV24/pedregosa11a.html}
}

@article{borner_sensor_2001,
  title = {{{SENSOR}}: A Tool for the Simulation of Hyperspectral Remote Sensing Systems},
  volume = {55},
  issn = {0924-2716},
  shorttitle = {{{SENSOR}}},
  doi = {10.1016/S0924-2716(01)00022-3},
  abstract = {The consistent end-to-end simulation of airborne and spaceborne earth remote sensing systems is an important task, and sometimes the only way for the \ldots},
  language = {en},
  number = {5-6},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  author = {B\"orner, Anko and Wiest, Lorenz and Keller, Peter and Reulke, Ralf and Richter, Rolf and Schaepman, Michael and Schl\"apfer, Daniel},
  month = mar,
  year = {2001},
  pages = {299-312},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/E63USYDR/S0924271601000223.html}
}

@article{davari_gmm-based_2018,
  title = {{{GMM}}-{{Based Synthetic Samples}} for {{Classification}} of {{Hyperspectral Images With Limited Training Data}}},
  volume = {15},
  issn = {1545-598X},
  doi = {10.1109/LGRS.2018.2817361},
  abstract = {The amount of training data that is required to train a classifier scales with the dimensionality of the feature data. In hyperspectral remote sensing (HSRS), feature data can potentially become very high dimensional. However, the amount of training data is oftentimes limited. Thus, one of the core challenges in HSRS is how to perform multiclass classification using only relatively few training data points. In this letter, we address this issue by enriching the feature matrix with synthetically generated sample points. These synthetic data are sampled from a Gaussian mixture model (GMM) fitted to each class of the limited training data. Although the true distribution of features may not be perfectly modeled by the fitted GMM, we demonstrate that a moderate augmentation by these synthetic samples can effectively replace a part of the missing training samples. Doing so, the median gain in classification performance is 5\% on two datasets. This performance gain is stable for variations in the number of added samples, which makes it easy to apply this method to real-world applications.},
  number = {6},
  journal = {IEEE Geoscience and Remote Sensing Letters},
  author = {Davari, Amir Abbas and Aptoula, Erchan and Yanikoglu, Berrin and Maier, Andreas and Riess, Christian},
  month = jun,
  year = {2018},
  keywords = {geophysical image processing,image classification,remote sensing,Gaussian processes,hyperspectral image classification,hyperspectral remote sensing,Standards,Hyperspectral imaging,Training data,Principal component analysis,Covariance matrices,GMM,Hyperspectral remote sensing (HSRS) image classification,limited training data,missing training samples,mixture models,synthetic data,synthetic samples,synthetically generated sample points},
  pages = {942-946},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/ZMAPGFCQ/8333743.html}
}

@article{lu_learning_2017,
  title = {Learning from {{Weak}} and {{Noisy Labels}} for {{Semantic Segmentation}}},
  volume = {39},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2016.2552172},
  abstract = {A weakly supervised semantic segmentation (WSSS) method aims to learn a segmentation model from weak (image-level) as opposed to strong (pixel-level) labels. By avoiding the tedious pixel-level annotation process, it can exploit the unlimited supply of user-tagged images from media-sharing sites such as Flickr for large scale applications. However, these â€˜free' tags/labels are often noisy and few existing works address the problem of learning with both weak and noisy labels. In this work, we cast the WSSS problem into a label noise reduction problem. Specifically, after segmenting each image into a set of superpixels, the weak and potentially noisy image-level labels are propagated to the superpixel level resulting in highly noisy labels; the key to semantic segmentation is thus to identify and correct the superpixel noisy labels. To this end, a novel L\textsubscript{1}-optimisation based sparse learning model is formulated to directly and explicitly detect noisy labels. To solve the L\textsubscript{1}-optimisation problem, we further develop an efficient learning algorithm by introducing an intermediate labelling variable. Extensive experiments on three benchmark datasets show that our method yields state-of-the-art results given noise-free labels, whilst significantly outperforming the existing methods when the weak labels are also noisy.},
  number = {3},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author = {Lu, Z. and Fu, Z. and Xiang, T. and Han, P. and Wang, L. and Gao, X.},
  month = mar,
  year = {2017},
  keywords = {Labeling,learning (artificial intelligence),optimisation,Computational modeling,Semantics,Training,image segmentation,Image segmentation,Semantic segmentation,free tag-labels,image denoising,image-level labels,L1-optimisation problem,label noise reduction,label noise reduction problem,learning problem,media-sharing sites,Noise measurement,Noise reduction,pixel-level annotation process,set theory,smart pixels,sparse learning,sparse learning model,superpixel level,superpixel noisy labels,user-tagged images,weak labels,weakly supervised learning,weakly supervised semantic segmentation,WSSS problem},
  pages = {486-500},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/QI9GFCH5/7450177.html}
}

@article{barriuso_notes_2012,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1210.3448},
  primaryClass = {cs},
  title = {Notes on Image Annotation},
  abstract = {We are under the illusion that seeing is effortless, but frequently the visual system is lazy and makes us believe that we understand something when in fact we don't. Labeling a picture forces us to become aware of the difficulties underlying scene understanding. Suddenly, the act of seeing is not effortless anymore. We have to make an effort in order to understand parts of the picture that we neglected at first glance. In this report, an expert image annotator relates her experience on segmenting and labeling tens of thousands of images. During this process, the notes she took try to highlight the difficulties encountered, the solutions adopted, and the decisions made in order to get a consistent set of annotations. Those annotations constitute the SUN database.},
  journal = {arXiv:1210.3448 [cs]},
  author = {Barriuso, Adela and Torralba, Antonio},
  month = oct,
  year = {2012},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Human-Computer Interaction},
  file = {/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/VSFYFIUK/Barriuso et Torralba - 2012 - Notes on image annotation.pdf;/home/naudeber/Nextcloud/Onera/Timeless/Bibliographie/.zotero/storage/GYWTAYLA/1210.html}
}


